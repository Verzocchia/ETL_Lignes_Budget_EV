{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree \n",
    "import time \n",
    "import logging\n",
    "import os\n",
    "import sqlite3\n",
    "import pathlib\n",
    "import glob\n",
    "import gzip \n",
    "import csv \n",
    "\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "\n",
    "DOSSIER_PARENT = \".\"\n",
    "DOSSIER_SOURCE = \"./todo/\"\n",
    "DOSSIER_SORTIE = \"./done/\"\n",
    "BDD = 'bdd_actes_budgetaires.db'\n",
    "FICHIER_CSV = 'donnees_actes_budgetaires.csv'\n",
    "FICHIERS_TO_DO= glob.glob(os.path.join(DOSSIER_SOURCE, \"*.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_decorator_x10x(func):\n",
    " def wrapper(*args, **kwargs):\n",
    "  total_time = 0\n",
    "  num_runs = 10\n",
    "  for _ in range(num_runs):\n",
    "   start_time = time.time()\n",
    "   func(*args, **kwargs)\n",
    "   end_time = time.time()\n",
    "   total_time += end_time - start_time\n",
    "   average_time = total_time / num_runs\n",
    "   print(f\"Temps moyen d'exécution de {func.__name__}: {average_time:.6f} secondes\")\n",
    " return wrapper\n",
    "\n",
    "def timing_decorator(func):\n",
    " def wrapper(*args, **kwargs):\n",
    "  start_time = time.time()\n",
    "  result = func(*args, **kwargs)\n",
    "  end_time = time.time()\n",
    "  execution_time = end_time - start_time\n",
    "  print(f\"{func.__name__} a pris {execution_time:.4f} secondes pour s'exécuter.\")\n",
    "  return result\n",
    " return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def parsing_fichier(chemin) : \n",
    " with gzip.open(chemin, 'rb') as fichier_ouvert : \n",
    "  fichier_xml_gzip = fichier_ouvert.read()\n",
    "  fichier_xml = fichier_xml_gzip.decode('latin-1')\n",
    "  fichier_dict = xmltodict.parse(fichier_xml)\n",
    " return fichier_dict\n",
    "\n",
    "def _extract_lignes_budget(data_dict: dict) -> pd.DataFrame : \n",
    " \"Sépare les sous clefs lignes budget, sans nettoyage\"\n",
    " ligne_budget = data_dict['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    " df_ligne_budget = pd.DataFrame(ligne_budget)\n",
    " return df_ligne_budget\n",
    "\n",
    "def _extract_id(fichier) -> dict :\n",
    " \"Extrait l'ID du nom du fichier, en fait un dict qui sera assemblé aux métadonnées\"\n",
    " val_IdFichier = fichier.split(\"-\")[-1].split('.')[0]\n",
    " IdFichier = {\"IdFichier\" : val_IdFichier}\n",
    " return IdFichier\n",
    "\n",
    "def _extract_metadonnees(data_dict : dict, IdFichier) -> pd.DataFrame : \n",
    " \"Sépare les sous clefs de métadonnées, sans nettoyage\"\n",
    " entete_dict = data_dict['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    " IdFichier_dict = _extract_id(IdFichier)\n",
    " metadonnees_dict = {**IdFichier_dict, **entete_dict}\n",
    " df_metadonnees = pd.DataFrame(metadonnees_dict)\n",
    " return df_metadonnees\n",
    "\n",
    "def extraction_donnees(data_dict : dict, fichier) -> pd.DataFrame :\n",
    " df_lignes_budget = _extract_lignes_budget(data_dict)\n",
    " df_metadonnees = _extract_metadonnees(data_dict, fichier)\n",
    " return df_lignes_budget, df_metadonnees\n",
    "\n",
    "def nettoyage_lambda(df : pd.DataFrame) -> pd.DataFrame : \n",
    " \"Nettoie les données pour se débarasser des @V\"\n",
    " nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    " for col in df.columns : \n",
    "  df[col] = df[col].apply(nettoyage)\n",
    " return df \n",
    "\n",
    "def assemblage_unitaire(df_lignes_budget : pd.DataFrame, df_metadonnees : pd.DataFrame) -> pd.DataFrame: \n",
    " \"\"\" Assemble les dataFrame contenant les metadonnees,\n",
    " la version schema et les lignes budgetaires \"\"\"\n",
    " colonnes_a_conserver = [\"IdFichier\", \"DteStr\", \"LibelleColl\",\n",
    "                         \"IdColl\",\"Nature\",\"LibCpte\",\n",
    "                         \"Fonction\",\"Operation\",\n",
    "                         \"ContNat\",\"ArtSpe\",\n",
    "                         \"ContFon\", \"ContOp\",\n",
    "                         \"CodRD\",\"MtBudgPrec\",\n",
    "                         \"MtRARPrec\",\"MtPropNouv\",\n",
    "                         \"MtPrev\",\"CredOuv\",\n",
    "                         \"MtReal\",\"MtRAR3112\",\n",
    "                         \"OpBudg\",\"TypOpBudg\",\n",
    "                         \"OpeCpteTiers\"\n",
    "                        ]\n",
    " df_metadonnees = pd.concat([df_metadonnees] * len(df_lignes_budget), ignore_index=True)\n",
    " df_concat = pd.concat([df_metadonnees, df_lignes_budget], axis = 1)\n",
    " df_fichier = pd.DataFrame(columns=colonnes_a_conserver)\n",
    "\n",
    " for i in df_concat.columns : \n",
    "    if i in colonnes_a_conserver :\n",
    "        df_fichier[i] = df_concat[i]\n",
    "\n",
    " df_fichier = df_fichier.dropna(axis = 1, how = 'all')\n",
    " return df_fichier\n",
    "\n",
    "def insertion_csv(df_final : pd.DataFrame) :\n",
    " ''' S'ajoute à un csv déjà existant, permet de ne pas créer un csv à chaque fois '''\n",
    " with open(FICHIER_CSV, 'a', newline='') as fichier_csv : \n",
    "  ajout = csv.writer(fichier_csv)\n",
    "  for _, ligne in df_final.iterrows():\n",
    "   ajout.writerow(ligne)\n",
    "\n",
    "def insertion_bdd(df_final: pd.DataFrame):\n",
    " \"\"\" insert dans une bdd les données maintenant transformées et en sort un csv à jour \"\"\"\n",
    " chemin_bdd = os.path.join(DOSSIER_PARENT, BDD)\n",
    " conn = sqlite3.connect(chemin_bdd)\n",
    " df_final.to_sql('actes_budgetaire', conn,\n",
    "                    if_exists='append', index=False)\n",
    "\n",
    "def deplacement_fichier(fichier_a_deplacer, dossier_destination):\n",
    " \"\"\" Déplace le fichier du dossier source au dossier fini\"\"\"\n",
    " chemin_source = pathlib.Path(fichier_a_deplacer)\n",
    " chemin_destination = pathlib.Path(dossier_destination) / chemin_source.name\n",
    " chemin_source.rename(chemin_destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolement_id(fichier) : \n",
    " \"Extrait l'id du nom du fichier pour la liste comprehension de securité\"\n",
    " val_IdFichier = fichier.split(\"-\")[-1].split('.')[0]\n",
    " return val_IdFichier\n",
    "\n",
    "def recherche_id_dans_bdd():\n",
    "    conn = sqlite3.connect(BDD)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(''' SELECT DISTINCT IdFichier FROM actes_budgetaire ''')\n",
    "    ligne_sql_int = [int(x[0]) for x in cursor.fetchall()]\n",
    "    conn.close()\n",
    "    return ligne_sql_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv() : \n",
    " with open(FICHIER_CSV, 'w', newline='') as csvfile:\n",
    "  header = \"IdFichier,DteStr,LibelleColl,IdColl,Nature,LibCpte,Fonction,Operation,ContNat,ArtSpe,ContFon,ContOp,CodRD,MtBudgPrec,MtRARPrec,MtPropNouv,MtPrev,CredOuv,MtReal,MtRAR3112,OpBudg,TypOpBudg,OpeCpteTiers\\n\"\n",
    "  csvfile.write(header)\n",
    "\n",
    "def clean_bdd() :  \n",
    " conn = sqlite3.connect(BDD)\n",
    " cursor = conn.cursor()\n",
    " cursor.execute('''DELETE FROM actes_budgetaire ''')\n",
    " conn.commit()\n",
    " conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_methode_unitaire():\n",
    " \"\"\" Traitement global, extrait et transforme les fichiers XML dans DOSSIER_SOURCE\n",
    "    pour les insérer dans une bdd et en faire un csv\"\"\"\n",
    " fichiers_safe = [fichier for fichier in FICHIERS_TO_DO if int(isolement_id(fichier)) not in recherche_id_dans_bdd()]\n",
    " for fichier in fichiers_safe : \n",
    "  fichier_parse = parsing_fichier(fichier)\n",
    "  df_lignes_budget, df_metadonnees = extraction_donnees(fichier_parse, fichier)\n",
    "  df_fichier = assemblage_unitaire(df_lignes_budget, df_metadonnees)\n",
    "  df_fichier_propre = nettoyage_lambda(df_fichier)\n",
    "  insertion_bdd(df_fichier_propre)\n",
    "  insertion_csv(df_fichier_propre)\n",
    "\n",
    "def main_solo(fichier): \n",
    "  fichier_parse = parsing_fichier(fichier)\n",
    "  df_lignes_budget, df_metadonnees = extraction_donnees(fichier_parse, fichier)\n",
    "  df_fichier = assemblage_unitaire(df_lignes_budget, df_metadonnees)\n",
    "  df_fichier_propre = nettoyage_lambda(df_fichier)\n",
    "  insertion_bdd(df_fichier_propre)\n",
    "  insertion_csv(df_fichier_propre)\n",
    "  return df_fichier_propre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_methode_unitaire()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_bdd()\n",
    "#clean_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichiers_safe = [fichier for fichier in FICHIERS_TO_DO if int(isolement_id(fichier)) not in recherche_id_dans_bdd()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_methode_unitaire()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
