{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'explication du script se fera de façon chronologique pour faciliter la compréhension, certaines fonctions seront ainsi expliquées après le script principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation bdd\n",
    "\n",
    "Se trouve dans le fichier creation_bdd.py.\n",
    "C'est un script simple permettant la création en externe de la base de données avec les colonnes et le type de données (à optimiser), cela permet de : \n",
    "- Ne pas créer la base de données en se basant sur le premier xml traité, ce qui pose problème lorsqu'un futur acte budgétaire contiendra plus d'informations (colonnes)\n",
    "- Pré-structurer les dates en date, certaines version du schema ne conservent pas les dates au même endroit ou de la même façon créant des conflits\n",
    "- Faciliter l'expérimentation du code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "BDD = 'bdd_actes_budgetaires_gz.db'\n",
    "\n",
    "def creation_bdd() : \n",
    " ''' Crée une base de données contenant les colonnes que nous allons chercher dans le script etl'''\n",
    " conn = sqlite3.connect(BDD)\n",
    " cursor = conn.cursor()\n",
    " cursor.execute('''\n",
    "  CREATE TABLE IF NOT EXISTS acte_budgetaire_gz ( \n",
    "    VersionSchema INT,\n",
    "    DteDec DATE,\n",
    "    LibelleColl TEXT,\n",
    "    IdColl INT,\n",
    "    Nature INT,\n",
    "    LibCpte TEXT,\n",
    "    Fonction INT,\n",
    "    Operation INT,\n",
    "    ContNat INT,\n",
    "    ArtSpe BOOLEAN,\n",
    "    ContFon INT,\n",
    "    ContOp INT,\n",
    "    CodRD TEXT,\n",
    "    MtBudgPrec INT,\n",
    "    MtRARPrec INT,\n",
    "    MtPropNouv REAL,\n",
    "    MtPrev REAL,\n",
    "    CredOuv REAL,\n",
    "    MtReal REAL,\n",
    "    MtRAR3112 INT,\n",
    "    OpBudg INT,\n",
    "    TypOpBudg INT,\n",
    "    OpeCpteTiers INT\n",
    "                ) \n",
    "                ''')\n",
    " conn.commit()\n",
    " conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    creation_bdd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etl_Fichier_GZ\n",
    "\n",
    "Décomposé en de nombreuses petites fonctions, le processus se fait de la façon suivante : \n",
    "- le script va chercher les fichiers xml.gz dans le dossier \"DOSSIER_SOURCE\"\n",
    "- Extraire les données que nous cherchons dans chaque fichier sous forme de df\n",
    "- Agglomérer les différents DataFrame (un par fichier)\n",
    "- Transformer les données afin de se débarasser des @V etc.\n",
    "- Déplacer les fichiers traités dans le dossier \"DOSSIER_SORTIE\"\n",
    "- Insérer le DataFrame aggloméré dans la base de données \"bdd_actes_budgetaires_gz.db\", dans le dossier \"DOSSIER_PARENT\"\n",
    "- Créer une copie de la base de données sous forme de csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOSSIER_PARENT = r\" \"\n",
    "DOSSIER_SOURCE = r\"./traitement en cours/\"\n",
    "DOSSIER_SORTIE = r\"./traite/\"\n",
    "BDD = 'bdd_actes_budgetaires_gz.db'\n",
    "NOM_CSV = 'donnees_budgetaires.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIMING_DECORATOR\n",
    "\n",
    "Optionnel, permet de calculer la vitesse des fonctions pour chercher des optimisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_decorator(func):\n",
    " def wrapper(*args, **kwargs):\n",
    "  start_time = time.time()\n",
    "  result = func(*args, **kwargs)\n",
    "  end_time = time.time()\n",
    "  execution_time = end_time - start_time\n",
    "  print(f\"{func.__name__} a pris {execution_time:.4f} secondes pour s'exécuter.\")\n",
    "  return result\n",
    " return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUVERTURE_GZIP\n",
    "\n",
    "Cherche le fichier .xml.gz, l'ouvre, le décode pour permettre sa lisibilité et transforme son contenu en dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ouverture_gzip(chemin) : \n",
    " with gzip.open(chemin, 'rb') as fichier_ouvert : \n",
    "  fichier_xml_gzip = fichier_ouvert.read()\n",
    "  fichier_xml = fichier_xml_gzip.decode('latin-1')\n",
    "  fichier_dict = xmltodict.parse(fichier_xml)\n",
    " return fichier_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARSING \n",
    "\n",
    "Ces fonctions vont individuellement chercher dans le dictionnaire nouvellement créer pour y chercher les informations voulues dans les différents sous dictionnaires : \n",
    "Les lignes budgets, l'en tête du document, la version du schema ainsi que la date d'envoi du fichier xml. Ensuite, chaque fonction va créer un mini DataFrame dont les données ne sont pas encore nettoyées (présence de @V etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_budget(data_dict: dict) -> pd.DataFrame : \n",
    " \"Sépare les sous clefs lignes budget, sans nettoyage\"\n",
    " ligne_budget = data_dict['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    " df_ligne_budget = pd.DataFrame(ligne_budget)\n",
    " return df_ligne_budget\n",
    "\n",
    "def parse_metadonnees(data_dict : dict) -> pd.DataFrame : \n",
    " \"Sépare les sous clefs de métadonnées, sans nettoyage\"\n",
    " metadonnees = data_dict['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    " df_metadonnees = pd.DataFrame(metadonnees)\n",
    " return df_metadonnees\n",
    "\n",
    "def parse_schema(data_dict : dict) -> pd.DataFrame : \n",
    " \"Sépare la version schema sans nettoyage\"\n",
    " version_schema = data_dict['DocumentBudgetaire']['VersionSchema']['@V']\n",
    " df_schema = pd.DataFrame({\"VersionSchema\": [version_schema]})\n",
    " return df_schema\n",
    "\n",
    "def parse_date(data_dict : dict) -> pd.DataFrame : \n",
    " date = data_dict['DocumentBudgetaire']['Budget']['BlocBudget']\n",
    " df_date = pd.DataFrame(date)\n",
    " return df_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSEMBLAGE\n",
    "\n",
    "Le but de cette fonction est d'assemblée les différents Dataframes issus des fonctions de parsing, de taille et de contenu différents. \n",
    "1. Premièrement, elle crée un DataFrame vide contenant les colonnes voulues (les mêmes que celle de la base de données)\n",
    "2. Elle \"corrige\" la taille des différents DataFrame : df_schema, df_date et df_metadonnees ne font qu'une ligne, la fonction \n",
    "   va multiplier la taille du dataframe par celle du df_principal (contenant les lignes budget) pour rendre la fusion possible\n",
    "3. les boucles for ont pour but que le df_final (contenant tout) copie les données de chaque dataframe partageant les colonnes. Cela permet de ne pas récupérer des données dont on ne souhaite pas, par exemple certaines métadonnées qui ont été extraites sans que ce soit intéressant pour nous\n",
    "4. Optionnel, les colonnes entièrement vides vont être supprimées (pratique pour les tests) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemblage(df_principal: pd.DataFrame, \n",
    "                         df_meta: pd.DataFrame, \n",
    "                         df_schem: pd.DataFrame,\n",
    "                         df_date : pd.DataFrame) -> pd.DataFrame:\n",
    " \"\"\" Assemble les dataFrame contenant les metadonnees,\n",
    " la version schema et les lignes budgetaires \"\"\"\n",
    " colonnes_a_conserver = [\"VersionSchema\", \"DteDec\", \"LibelleColl\",\n",
    "                         \"IdColl\",\"Nature\",\"LibCpte\",\n",
    "                         \"Fonction\",\"Operation\",\n",
    "                         \"ContNat\",\"ArtSpe\",\n",
    "                         \"ContFon\", \"ContOp\",\n",
    "                         \"CodRD\",\"MtBudgPrec\",\n",
    "                         \"MtRARPrec\",\"MtPropNouv\",\n",
    "                         \"MtPrev\",\"CredOuv\",\n",
    "                         \"MtReal\",\"MtRAR3112\",\n",
    "                         \"OpBudg\",\"TypOpBudg\",\n",
    "                         \"OpeCpteTiers\"\n",
    "                        ]\n",
    " \n",
    " df_final = pd.DataFrame(columns=colonnes_a_conserver)\n",
    " df_schem = pd.concat([df_schem] * len(df_principal), ignore_index=True)\n",
    " df_meta = pd.concat([df_meta] * len(df_principal), ignore_index=True)\n",
    " df_date = pd.concat([df_date] * len(df_principal), ignore_index=True)\n",
    "\n",
    " for col in df_schem.columns:\n",
    "  if col in colonnes_a_conserver:\n",
    "    df_final[col] = df_schem[col]\n",
    "\n",
    " for col in df_meta.columns:\n",
    "  if col in colonnes_a_conserver:\n",
    "    df_final[col] = df_meta[col]\n",
    "\n",
    " for col in df_principal.columns:\n",
    "  if col in colonnes_a_conserver:\n",
    "    df_final[col] = df_principal[col]\n",
    "\n",
    " for col in df_date.columns:\n",
    "  if col in colonnes_a_conserver:\n",
    "    df_final[col] = df_date[col]\n",
    "\n",
    " df_final = df_final.dropna(axis=1, how='all')\n",
    " return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPLACEMENT FICHIER\n",
    "\n",
    "Cette fonction va simplement déplacer, en fin de traitement individuel, le fichier traité du DOSSIER_SOURCE au DOSSIER_SORTIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deplacement_fichier(fichier_a_deplacer, dossier_destination):\n",
    " \"\"\" Déplace le fichier du dossier source au dossier fini\"\"\"\n",
    " chemin_source = pathlib.Path(fichier_a_deplacer)\n",
    " chemin_destination = pathlib.Path(dossier_destination) / chemin_source.name\n",
    " chemin_source.rename(chemin_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FONCTION MAIN partie 1\n",
    "\n",
    "- La fonction traite, dans la partie 1 les fichiers du DOSSIER_SOURCE un par un. \n",
    "- La première boucle for consiste à vérifier que les fichiers dans le DOSSIER_SOURCE ne sont pas déjà dans le DOSSIER_SORTIE (signifiant qu'ils ont déjà été traités),    évitant des doublons dans la base de données. \n",
    "- Pour chaque fichier, la fonction main va ouvrir le fichier, le transformer en dict (via ouverture_gzip), extraire et transformer en DataFrame les parties voulues puis assembler ces parties, enfin le fichier sera déplacé dans le DOSSIER_SORTIE, signifiant que ses données ont été extraites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    " \"\"\" Traitement global, extrait et transforme les fichiers XML dans DOSSIER_SOURCE\n",
    "    pour les insérer dans une bdd et en faire un csv\"\"\"\n",
    " liste_des_fichier_source = glob.glob(os.path.join(DOSSIER_SOURCE, \"*.gz\"))\n",
    " liste_des_fichier_traite = glob.glob(os.path.join(DOSSIER_SORTIE, \"*.gz\"))\n",
    " liste_des_df = []\n",
    " for fichier in liste_des_fichier_source:\n",
    "  logging.info(f'Debut du travail sur {fichier}')\n",
    "    # Sécurité permettant de ne pas injecter des doublons\n",
    "  if fichier in liste_des_fichier_traite : \n",
    "   logging.error(f'Le fichier {fichier} a déjà été traité')\n",
    "   return None \n",
    "  else : \n",
    "   data_dict = ouverture_gzip(fichier)\n",
    "   if data_dict is not None:\n",
    "    df_budget = parse_budget(data_dict)\n",
    "    df_metadonnees = parse_metadonnees(data_dict)\n",
    "    df_schema = parse_schema(data_dict)\n",
    "    df_date = parse_date(data_dict)\n",
    "    if df_budget is not None \\\n",
    "            and df_metadonnees is not None \\\n",
    "            and df_schema is not None \\\n",
    "            and df_date is not None:\n",
    "     df_final = assemblage(\n",
    "                df_budget, df_metadonnees, df_schema, df_date)\n",
    "     liste_des_df.append(df_final)\n",
    "     logging.info(f'Fin du travail sur {fichier}')\n",
    "     deplacement_fichier(fichier, DOSSIER_SORTIE)\n",
    "  #Séparation entre la partie 1 et 2 de la fonction main\n",
    " df_session = pd.concat(liste_des_df, ignore_index = True)\n",
    " nettoyage_lambda(df_session)\n",
    " insertion_bdd(df_session)\n",
    " creation_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LISTE_DES_DF & DF_SESSION\n",
    "\n",
    "A chaque boucle de la partie un, un DataFrame est ajouté à la liste des dataframe, puis ils sont tous agglomérés pour pouvoir être traités. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETTOYAGE LAMBDA\n",
    "\n",
    "En théorie, à cette étape, les fichiers du DOSSIER_SOURCE sont tous traités, les données voulues ne forment qu'un seul DataFrame.\n",
    "Cette fonction a pour but, d'appliquer colonnes par colonnes une fonction lambda de nettoyage, retirant les '@V: ' des données.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyage_lambda(df : pd.DataFrame) -> pd.DataFrame : \n",
    " \"Nettoie les données pour se débarasser des @V\"\n",
    " nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    " for col in df.columns : \n",
    "  df[col] = df[col].apply(nettoyage)\n",
    " return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
