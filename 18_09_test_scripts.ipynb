{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import logging\n",
    "import os\n",
    "import sqlite3\n",
    "import pathlib\n",
    "import glob\n",
    "import gzip \n",
    "\n",
    "import pandas as pd\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insertion dans BDD v2 (bdd déjà existante et contient toutes les col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coeur intouchable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOSSIER_PARENT = r\" \"\n",
    "DOSSIER_SOURCE = r\"./traitement en cours/\"\n",
    "DOSSIER_SORTIE = r\"./traite/\"\n",
    "BDD = 'bdd_actes_budgetaires_gz.db'\n",
    "NOM_CSV = 'donnees_budgetaires.csv'\n",
    "\n",
    "def ouverture_gzip(chemin) : \n",
    " with gzip.open(chemin, 'rb') as fichier_ouvert : \n",
    "  fichier_xml_gzip = fichier_ouvert.read()\n",
    "  fichier_xml = fichier_xml_gzip.decode('latin-1')\n",
    "  fichier_dict = xmltodict.parse(fichier_xml)\n",
    " return fichier_dict\n",
    "\n",
    "def timing_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"{func.__name__} a pris {execution_time:.4f} secondes pour s'exécuter.\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification à chaque parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fichier_xml(chemin) -> dict:\n",
    "    \"\"\" Transforme le fichier xml en dictionnaire python \"\"\"\n",
    "    with open(chemin, \"r\", encoding=\"latin-1\") as fichier_ouvert:\n",
    "        fichier_xml = fichier_ouvert.read()\n",
    "        data_dict = xmltodict.parse(fichier_xml)\n",
    "    return data_dict\n",
    "\n",
    "def parse_budget(data_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\" Sépare les sous clefs lignes budgets ainsi que leur contenu du reste \"\"\"\n",
    "    ligne_budget = data_dict['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "    for mini_dict in ligne_budget:\n",
    "        for key, value in mini_dict.items():\n",
    "            if isinstance(value, dict) and '@V' in value:\n",
    "                mini_dict[key] = value['@V']\n",
    "    df_budget = pd.DataFrame(ligne_budget)\n",
    "    return df_budget\n",
    "\n",
    "\n",
    "def parse_metadonnes(data_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\" Sépare et isole les metadonnees du document \"\"\"\n",
    "    en_tete_data = data_dict['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    "    df_metadonnees = pd.json_normalize(en_tete_data)\n",
    "    df_metadonnees.columns = df_metadonnees.columns.str.replace('.@V', '')\n",
    "    return df_metadonnees\n",
    "\n",
    "\n",
    "def parse_version_schema(data_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\" Extrait la version schema du document \"\"\"\n",
    "    version_schema = data_dict['DocumentBudgetaire']['VersionSchema']['@V']\n",
    "    df_schema = pd.DataFrame({\"VersionSchema\": [version_schema]})\n",
    "    return df_schema\n",
    "\n",
    "def parse_date(data_dict : dict) -> pd.DataFrame : \n",
    " date = data_dict['DocumentBudgetaire']['Budget']['BlocBudget']['DteDec']['@V']\n",
    " df_date = pd.DataFrame({\"DteDec\" : [date]})\n",
    " return df_date\n",
    "\n",
    "# Version safe de l'assemblage, plus rigide,\n",
    "# n'accepte pas des colonnes non existantes\n",
    "\n",
    "@timing_decorator\n",
    "def assemblage(df_principal: pd.DataFrame,\n",
    "               df_meta: pd.DataFrame,\n",
    "               df_schem: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Assemble les dataFrame contneant les metadonnees, \n",
    "    la version schema et les lignes budgetaires \"\"\"\n",
    "    colonnes_a_conserver = [\"Nature\",\"LibCpte\",\n",
    "                            \"Fonction\",\"Operation\",\n",
    "                            \"ContNat\",\"ArtSpe\",\n",
    "                            \"ContFon\", \"ContOp\",\n",
    "                            \"CodRD\",\"MtBudgPrec\",\n",
    "                            \"MtRARPrec\",\"MtPropNouv\",\n",
    "                            \"MtPrev\",\"CredOuv\",\n",
    "                            \"MtReal\",\"MtRAR3112\",\n",
    "                            \"OpBudg\",\"TypOpBudg\",\n",
    "                            \"OpeCpteTiers\", \"MtSup\" , \n",
    "                            \"CaracSup\"] \n",
    "    df_schem = pd.concat([df_schem] * len(df_principal), ignore_index=True)\n",
    "    df_meta = pd.concat([df_meta] * len(df_principal), ignore_index=True)\n",
    "    df_principal = pd.concat([df_schem, df_meta, df_principal], axis=1)\n",
    "    df_principal = df_principal[colonnes_a_conserver]\n",
    "    return df_principal\n",
    "\n",
    "# 2eme version, plus flexible (exemple avec la colonne test \"bonjour\"),\n",
    "# les boucles for ne gênent pas car ne s'attaquent qu'aux colonnes,\n",
    "#  donnent une bdd et un csv avec le même contenu\n",
    "\n",
    "def assemblage_bricolage(df_principal: pd.DataFrame, \n",
    "                         df_meta: pd.DataFrame, \n",
    "                         df_schem: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Assemble les dataFrame contenant les metadonnees, \n",
    "    la version schema et les lignes budgetaires \"\"\"\n",
    "    colonnes_a_conserver = [\"VersionSchema\", \"DteDec\", \"LibelleColl\",\n",
    "                            \"IdColl\",\"Nature\",\"LibCpte\",\n",
    "                            \"Fonction\",\"Operation\",\n",
    "                            \"ContNat\",\"ArtSpe\",\n",
    "                            \"ContFon\", \"ContOp\",\n",
    "                            \"CodRD\",\"MtBudgPrec\",\n",
    "                            \"MtRARPrec\",\"MtPropNouv\",\n",
    "                            \"MtPrev\",\"CredOuv\",\n",
    "                            \"MtReal\",\"MtRAR3112\",\n",
    "                            \"OpBudg\",\"TypOpBudg\",\n",
    "                            \"OpeCpteTiers\"]\n",
    "    df_final = pd.DataFrame(columns=colonnes_a_conserver)\n",
    "    df_schem = pd.concat([df_schem] * len(df_principal), ignore_index=True)\n",
    "    df_meta = pd.concat([df_meta] * len(df_principal), ignore_index=True)\n",
    "\n",
    "    for colonne in df_schem.columns:\n",
    "        if colonne in colonnes_a_conserver:\n",
    "            df_final[colonne] = df_schem[colonne]\n",
    "\n",
    "    for colonne in df_meta.columns:\n",
    "        if colonne in colonnes_a_conserver:\n",
    "            df_final[colonne] = df_meta[colonne]\n",
    "\n",
    "    for colonne in df_principal.columns:\n",
    "        if colonne in colonnes_a_conserver:\n",
    "            df_final[colonne] = df_principal[colonne]\n",
    "\n",
    "    df_final = df_final.dropna(axis=1, how='all')\n",
    "    return df_final\n",
    "\n",
    "\n",
    "def insertion_bdd(df_final: pd.DataFrame):\n",
    " \"\"\" insert dans une bdd les données maintenant transformées et en sort un csv à jour \"\"\"\n",
    " chemin_bdd = os.path.join(DOSSIER_PARENT, BDD)\n",
    " conn = sqlite3.connect(chemin_bdd)\n",
    " df_final.to_sql('acte_budgetaire_gz', conn,\n",
    "                    if_exists='append', index=False)\n",
    "\n",
    "def creation_csv() :\n",
    " conn = sqlite3.connect(BDD)\n",
    " cursor = conn.cursor()\n",
    " info = cursor.execute('''Select * from acte_budgetaire_gz''')\n",
    " df = pd.DataFrame(info)\n",
    " fichier_csv = os.path.join(DOSSIER_PARENT, NOM_CSV)\n",
    " df.to_csv(fichier_csv, index=False)\n",
    " conn.close()\n",
    "\n",
    "def deplacement_fichier(fichier_a_deplacer, dossier_destination):\n",
    "    \"\"\" Déplace le fichier du dossier source au dossier fini\"\"\"\n",
    "    chemin_source = pathlib.Path(fichier_a_deplacer)\n",
    "    chemin_destination = pathlib.Path(dossier_destination) / chemin_source.name\n",
    "    chemin_source.rename(chemin_destination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version assemblage puis traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v2_parse_budget(data_dict: dict) -> pd.DataFrame : \n",
    " \"Sépare les sous clefs lignes budget, sans nettoyage\"\n",
    " ligne_budget = data_dict['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    " df_ligne_budget = pd.DataFrame(ligne_budget)\n",
    " return df_ligne_budget\n",
    "\n",
    "def v2_parse_metadonnees(data_dict : dict) -> pd.DataFrame : \n",
    " \"Sépare les sous clefs de métadonnées, sans nettoyage\"\n",
    " metadonnees = data_dict['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    " df_metadonnees = pd.DataFrame(metadonnees)\n",
    " return df_metadonnees\n",
    "\n",
    "def v2_parse_schema(data_dict : dict) -> pd.DataFrame : \n",
    " \"Sépare la version schema sans nettoyage\"\n",
    " version_schema = data_dict['DocumentBudgetaire']['VersionSchema']['@V']\n",
    " df_schema = pd.DataFrame({\"VersionSchema\": [version_schema]})\n",
    " return df_schema\n",
    "\n",
    "def v2_parse_date(data_dict : dict) -> pd.DataFrame : \n",
    " date = data_dict['DocumentBudgetaire']['Budget']['BlocBudget']\n",
    " df_date = pd.DataFrame(date)\n",
    " return df_date\n",
    "\n",
    "def v2_assemblage(df_principal: pd.DataFrame, \n",
    "                         df_meta: pd.DataFrame, \n",
    "                         df_schem: pd.DataFrame,\n",
    "                         df_date : pd.DataFrame) -> pd.DataFrame:\n",
    " \"\"\" Assemble les dataFrame contenant les metadonnees,\n",
    " la version schema et les lignes budgetaires \"\"\"\n",
    " colonnes_a_conserver = [\"VersionSchema\", \"DteDec\", \"LibelleColl\",\n",
    "                         \"IdColl\",\"Nature\",\"LibCpte\",\n",
    "                         \"Fonction\",\"Operation\",\n",
    "                         \"ContNat\",\"ArtSpe\",\n",
    "                         \"ContFon\", \"ContOp\",\n",
    "                         \"CodRD\",\"MtBudgPrec\",\n",
    "                         \"MtRARPrec\",\"MtPropNouv\",\n",
    "                         \"MtPrev\",\"CredOuv\",\n",
    "                         \"MtReal\",\"MtRAR3112\",\n",
    "                         \"OpBudg\",\"TypOpBudg\",\n",
    "                         \"OpeCpteTiers\"\n",
    "                        ]\n",
    " \n",
    " df_final = pd.DataFrame(columns=colonnes_a_conserver)\n",
    " df_schem = pd.concat([df_schem] * len(df_principal), ignore_index=True)\n",
    " df_meta = pd.concat([df_meta] * len(df_principal), ignore_index=True)\n",
    " df_date = pd.concat([df_date] * len(df_principal), ignore_index=True)\n",
    "\n",
    " for col in df_schem.columns:\n",
    "  if col in colonnes_a_conserver:\n",
    "    df_final[col] = df_schem[col]\n",
    "\n",
    " for col in df_meta.columns:\n",
    "  if col in colonnes_a_conserver:\n",
    "    df_final[col] = df_meta[col]\n",
    "\n",
    " for col in df_principal.columns:\n",
    "  if col in colonnes_a_conserver:\n",
    "    df_final[col] = df_principal[col]\n",
    "\n",
    " for col in df_date.columns:\n",
    "  if col in colonnes_a_conserver:\n",
    "    df_final[col] = df_date[col]\n",
    "\n",
    " df_final = df_final.dropna(axis=1, how='all')\n",
    " return df_final\n",
    "\n",
    "def v2_nettoyage_lambda(df : pd.DataFrame) -> pd.DataFrame : \n",
    " \"Nettoie les données pour se débarasser des @V\"\n",
    " nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    " for col in df.columns : \n",
    "  df[col] = df[col].apply(nettoyage)\n",
    " return df \n",
    "\n",
    "def v2_test_clean(df : pd.DataFrame) : \n",
    " df.replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    " return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script v1 : traitement à chaque parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def main_v1():\n",
    " \"\"\" Traitement global, extrait et transforme les fichiers XML dans DOSSIER_SOURCE\n",
    "    pour les insérer dans une bdd et en faire un csv\"\"\"\n",
    " liste_des_fichier_source = glob.glob(os.path.join(DOSSIER_SOURCE, \"*.gz\"))\n",
    " liste_des_fichier_traite = glob.glob(os.path.join(DOSSIER_SORTIE, \"*.gz\"))\n",
    " for fichier in liste_des_fichier_source:\n",
    "  logging.info(f'Debut du travail sur {fichier}')\n",
    "    # Sécurité permettant de ne pas injecter des doublons\n",
    "  if fichier in liste_des_fichier_traite : \n",
    "   logging.error(f'Le fichier {fichier} a déjà été traité')\n",
    "   return None\n",
    "  else : \n",
    "   data_dict = ouverture_gzip(fichier)\n",
    "   if data_dict is not None:\n",
    "    df_budget = parse_budget(data_dict)\n",
    "    df_metadonnees = parse_metadonnes(data_dict)\n",
    "    df_schema = parse_version_schema(data_dict)\n",
    "    if df_budget is not None \\\n",
    "            and df_metadonnees is not None \\\n",
    "            and df_schema is not None:\n",
    "     df_final = assemblage_bricolage(\n",
    "                df_budget, df_metadonnees, df_schema)\n",
    "     insertion_bdd(df_final)\n",
    "     deplacement_fichier(fichier, DOSSIER_SORTIE)\n",
    "     logging.info(f'Fin du travail sur {fichier}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assemblage_bricolage a pris 0.0200 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0509 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0500 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0250 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0500 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0270 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0500 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0581 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0260 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0530 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0380 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0370 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0540 secondes pour s'exécuter.\n",
      "assemblage_bricolage a pris 0.0430 secondes pour s'exécuter.\n",
      "main_v1 a pris 11.0385 secondes pour s'exécuter.\n"
     ]
    }
   ],
   "source": [
    "main_v1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script v2 : traitement à chaque assemblage (fichier par fichier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def main_v2():\n",
    " \"\"\" Traitement global, extrait et transforme les fichiers XML dans DOSSIER_SOURCE\n",
    "    pour les insérer dans une bdd et en faire un csv\"\"\"\n",
    " liste_des_fichier_source = glob.glob(os.path.join(DOSSIER_SOURCE, \"*.gz\"))\n",
    " liste_des_fichier_traite = glob.glob(os.path.join(DOSSIER_SORTIE, \"*.gz\"))\n",
    " for fichier in liste_des_fichier_source:\n",
    "  logging.info(f'Debut du travail sur {fichier}')\n",
    "    # Sécurité permettant de ne pas injecter des doublons\n",
    "  if fichier in liste_des_fichier_traite : \n",
    "   logging.error(f'Le fichier {fichier} a déjà été traité')\n",
    "   return None\n",
    "  else : \n",
    "   data_dict = ouverture_gzip(fichier)\n",
    "   if data_dict is not None:\n",
    "    df_budget = v2_parse_budget(data_dict)\n",
    "    df_metadonnees = v2_parse_metadonnees(data_dict)\n",
    "    df_schema = v2_parse_schema(data_dict)\n",
    "    df_date = v2_parse_date(data_dict)\n",
    "    if df_budget is not None \\\n",
    "            and df_metadonnees is not None \\\n",
    "            and df_schema is not None \\\n",
    "            and df_date is not None:\n",
    "     df_final = v2_assemblage(\n",
    "                df_budget, df_metadonnees, df_schema, df_date)\n",
    "     v2_nettoyage_lambda(df_final)\n",
    "     insertion_bdd(df_final)\n",
    "     deplacement_fichier(fichier, DOSSIER_SORTIE)\n",
    "\n",
    "     logging.info(f'Fin du travail sur {fichier}')\n",
    " creation_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: ' '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\projets data\\budget_communes\\18_09_test_scripts.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main_v2()\n",
      "\u001b[1;32md:\\projets data\\budget_communes\\18_09_test_scripts.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     execution_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32md:\\projets data\\budget_communes\\18_09_test_scripts.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     deplacement_fichier(fichier, DOSSIER_SORTIE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFin du travail sur \u001b[39m\u001b[39m{\u001b[39;00mfichier\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m creation_csv()\n",
      "\u001b[1;32md:\\projets data\\budget_communes\\18_09_test_scripts.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(info)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m fichier_csv \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DOSSIER_PARENT, NOM_CSV)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(fichier_csv, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X16sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m conn\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1154\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 739\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    741\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    742\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    743\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    602\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: ' '"
     ]
    }
   ],
   "source": [
    "main_v2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction clean bdd pour les test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bdd_test() : \n",
    " conn = sqlite3.connect(BDD)\n",
    " cursor = conn.cursor()\n",
    " cursor.execute('''DELETE FROM acte_budgetaire_gz ''')\n",
    " conn.commit()\n",
    " conn.close()\n",
    "\n",
    "clean_bdd_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script v3: traitement par bloc de fichier (dossier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def main_v3():\n",
    " \"\"\" Traitement global, extrait et transforme les fichiers XML dans DOSSIER_SOURCE\n",
    "    pour les insérer dans une bdd et en faire un csv\"\"\"\n",
    " liste_des_fichier_source = glob.glob(os.path.join(DOSSIER_SOURCE, \"*.gz\"))\n",
    " liste_des_fichier_traite = glob.glob(os.path.join(DOSSIER_SORTIE, \"*.gz\"))\n",
    " liste_des_df = []\n",
    " for fichier in liste_des_fichier_source:\n",
    "  logging.info(f'Debut du travail sur {fichier}')\n",
    "    # Sécurité permettant de ne pas injecter des doublons\n",
    "  if fichier in liste_des_fichier_traite : \n",
    "   logging.error(f'Le fichier {fichier} a déjà été traité')\n",
    "   return None \n",
    "  else : \n",
    "   data_dict = ouverture_gzip(fichier)\n",
    "   if data_dict is not None:\n",
    "    df_budget = v2_parse_budget(data_dict)\n",
    "    df_metadonnees = v2_parse_metadonnees(data_dict)\n",
    "    df_schema = v2_parse_schema(data_dict)\n",
    "    df_date = v2_parse_date(data_dict)\n",
    "    if df_budget is not None \\\n",
    "            and df_metadonnees is not None \\\n",
    "            and df_schema is not None \\\n",
    "            and df_date is not None:\n",
    "     df_final = v2_assemblage(\n",
    "                df_budget, df_metadonnees, df_schema, df_date)\n",
    "     liste_des_df.append(df_final)\n",
    "     logging.info(f'Fin du travail sur {fichier}')\n",
    "     deplacement_fichier(fichier, DOSSIER_SORTIE)\n",
    " df_session = pd.concat(liste_des_df, ignore_index = True)\n",
    " v2_nettoyage_lambda(df_session)\n",
    " insertion_bdd(df_session)\n",
    " creation_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\projets data\\budget_communes\\18_09_test_scripts.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main_v3()\n",
      "\u001b[1;32md:\\projets data\\budget_communes\\18_09_test_scripts.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     execution_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32md:\\projets data\\budget_communes\\18_09_test_scripts.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFin du travail sur \u001b[39m\u001b[39m{\u001b[39;00mfichier\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     deplacement_fichier(fichier, DOSSIER_SORTIE)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m df_session \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(liste_des_df, ignore_index \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m v2_nettoyage_lambda(df_session)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projets%20data/budget_communes/18_09_test_scripts.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m insertion_bdd(df_session)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    378\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    383\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    384\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    385\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    386\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    387\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    388\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    389\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    390\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[0;32m    393\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_integrity \u001b[39m=\u001b[39m verify_integrity\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39m=\u001b[39m copy\n\u001b[1;32m--> 443\u001b[0m objs, keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    445\u001b[0m \u001b[39m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    446\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    502\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[0;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    507\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "main_v3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
