{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip \n",
    "from lxml import etree\n",
    "import pandas as pd \n",
    "import xmltodict\n",
    "import glob\n",
    "import os \n",
    "import time \n",
    "import polars as pl \n",
    "import duckdb\n",
    "import shutil \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOSSIER_500 = \"./todo/test1000_2/\"\n",
    "DOSSIER_TODO = './fichiers/todo_xml/'\n",
    "DOSSIER_PARQUET_UNITAIRE = './fichiers/todo_parquet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timtim(fonction):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        debut = time.time()\n",
    "        resultat = fonction(*args, **kwargs)\n",
    "        fin = time.time()\n",
    "        temps_execution = fin - debut\n",
    "        print(f\"La fonction {fonction.__name__} a pris {temps_execution:.5f} secondes pour s'exécuter.\")\n",
    "        return resultat\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fichier(chemin) : \n",
    " '''Ouvre et parse le fichier gzip'''\n",
    " with gzip.open(chemin, 'rb') as fichier_ouvert : \n",
    "  fichier_xml_gzip = fichier_ouvert.read()\n",
    "  fichier_xml = fichier_xml_gzip.decode('latin-1')\n",
    "  fichier_dict = xmltodict.parse(fichier_xml)\n",
    " return fichier_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timtim\n",
    "def Methode_1(chemin) : \n",
    " liste_df = []\n",
    " for fichier in glob.glob(os.path.join(chemin, \"*.gz\")) : \n",
    "  try : \n",
    "   dico = parse_fichier(fichier)\n",
    "   docbase = dico['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "   liste_methode_1 = []\n",
    "   for ligne_methode_1 in docbase:\n",
    "     dict_temp = {}\n",
    "     for clef, valolo in ligne_methode_1.items():\n",
    "         if isinstance(valolo, dict) and '@V' in valolo:\n",
    "             val_atrib = valolo['@V']\n",
    "         else:\n",
    "             val_atrib = valolo\n",
    "         dict_temp[clef] = val_atrib\n",
    "     liste_methode_1.append(dict_temp)\n",
    "   df_methode_1 = pd.DataFrame(liste_methode_1)\n",
    "   liste_df.append(df_methode_1)\n",
    "  except Exception as e :\n",
    "   print(f'Erreur fichier {fichier}') \n",
    "   continue \n",
    " \n",
    " df_gros_1 = pd.concat(liste_df)\n",
    " return df_gros_1\n",
    "\n",
    "@timtim\n",
    "def Methode_2(chemin) : \n",
    " liste_df = []\n",
    " for fichier in glob.glob(os.path.join(chemin, \"*.gz\")) : \n",
    "  try : \n",
    "   dico = parse_fichier(fichier)\n",
    "   docbase = dico['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "   df_methode_2 = pd.DataFrame(docbase)\n",
    "   nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    "   for col in df_methode_2.columns : \n",
    "    if col in ['MtSup', 'CaracSup'] : \n",
    "     continue \n",
    "    else :\n",
    "     df_methode_2[col] = df_methode_2[col].apply(nettoyage)\n",
    "   #colonnes_a_exclure = ['MtSup', 'CaracSup']\n",
    "   #nettoyage = lambda x: str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\") if x.name not in colonnes_a_exclure else x\n",
    "   #df_methode_2 = df_methode_2.apply(nettoyage)\n",
    "   liste_df.append(df_methode_2)\n",
    "  except Exception as e : \n",
    "    print(f'Erreur fichier {fichier}')\n",
    "    continue\n",
    "   \n",
    " gros_df_2 = pd.concat(liste_df)\n",
    " return gros_df_2\n",
    "\n",
    "@timtim\n",
    "def Methode_2_test(chemin) : \n",
    " liste_df = []\n",
    " for fichier in glob.glob(os.path.join(chemin, \"*.gz\")) : \n",
    "  try : \n",
    "   dico = parse_fichier(fichier)\n",
    "   docbase = dico['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "   df_methode_2 = pd.DataFrame(docbase)\n",
    "   #colonnes_a_exclure = ['MtSup', 'CaracSup']\n",
    "   #nettoyage = lambda x: str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\") if x.name not in colonnes_a_exclure else x\n",
    "   #df_methode_2 = df_methode_2.apply(nettoyage)\n",
    "   liste_df.append(df_methode_2)\n",
    "  except Exception as e : \n",
    "    print(f'Erreur fichier {fichier}')\n",
    "    continue  \n",
    "\n",
    " gros_df_2 = pd.concat(liste_df)\n",
    " nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    " for col in gros_df_2.columns : \n",
    "    if col in ['MtSup', 'CaracSup'] : \n",
    "     continue \n",
    "    else :\n",
    "     gros_df_2[col] = gros_df_2[col].apply(nettoyage)\n",
    " gros_df_2 = gros_df_2.reset_index(drop=True)\n",
    " return gros_df_2 \n",
    "\n",
    "@timtim\n",
    "def Methode_3(chemin) : \n",
    " liste_df = []\n",
    " for fichier in glob.glob(os.path.join(chemin, \"*.gz\")) : \n",
    "  try : \n",
    "   dico = parse_fichier(fichier)\n",
    "   docbase = dico['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "   df_methode_3 = pd.json_normalize(docbase)\n",
    "   liste_df.append(df_methode_3)\n",
    "  except Exception as e : \n",
    "    print(f'Erreur fichier {fichier}')\n",
    "    continue\n",
    " gros_df_3 = pd.concat(liste_df)\n",
    " return gros_df_3\n",
    "\n",
    "SCHEMA = {\"Nature\" : pl.Object,\n",
    "          \"LibCpte\" : pl.Object,\n",
    "          \"Fonction\" : pl.Object,\n",
    "          \"Operation\" : pl.Object,\n",
    "          \"ContNat\" : pl.Object,\n",
    "          \"ArtSpe\" : pl.Object,\n",
    "          \"ContFon\" : pl.Object,\n",
    "          \"ContOp\" : pl.Object,\n",
    "          \"CodRD\" : pl.Object,\n",
    "          \"MtBudgPrec\" : pl.Object,\n",
    "          \"MtRARPrec\" : pl.Object,\n",
    "          \"MtPropNouv\" : pl.Object,\n",
    "          \"MtPrev\" : pl.Object,\n",
    "          \"CredOuv\" : pl.Object,\n",
    "          \"MtReal\" : pl.Object,\n",
    "          \"MtRAR3112\" : pl.Object,\n",
    "          \"OpBudg\" : pl.Object,\n",
    "          \"TypOpBudg\" : pl.Object,\n",
    "          \"OpeCpteTiers\" : pl.Object, \n",
    "          \"MtSup\" : pl.Object, \n",
    "          \"CaracSup\" : pl.Object\n",
    "          }\n",
    "\n",
    "@timtim\n",
    "def Methode_polars(chemin, schema) : \n",
    " liste_prepl = []\n",
    " for fichier in glob.glob(os.path.join(chemin, \"*.gz\")) : \n",
    "  try : \n",
    "   dico = parse_fichier(fichier)\n",
    "   docbase = dico['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "   pre_df = pl.DataFrame(docbase, schema=schema)\n",
    "   liste_prepl.append(pre_df)\n",
    "  except Exception as e : \n",
    "    print(f'Erreur fichier {fichier}')\n",
    "    continue\n",
    " pl_test = pl.concat(liste_prepl)\n",
    " return pl_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur fichier ./todo\\619027.xml.gz\n",
      "Erreur fichier ./todo\\628857.xml.gz\n",
      "Erreur fichier ./todo\\682109.xml.gz\n",
      "Erreur fichier ./todo\\722795.xml.gz\n",
      "Erreur fichier ./todo\\730073.xml.gz\n",
      "Erreur fichier ./todo\\748147.xml.gz\n",
      "Erreur fichier ./todo\\756300.xml.gz\n",
      "Erreur fichier ./todo\\775775.xml.gz\n",
      "Erreur fichier ./todo\\807134.xml.gz\n",
      "Erreur fichier ./todo\\809162.xml.gz\n",
      "Erreur fichier ./todo\\809290.xml.gz\n",
      "Erreur fichier ./todo\\819789.xml.gz\n",
      "Erreur fichier ./todo\\821461.xml.gz\n",
      "Erreur fichier ./todo\\838663.xml.gz\n",
      "La fonction Methode_1 a pris 341.08701 secondes pour s'exécuter.\n"
     ]
    }
   ],
   "source": [
    "dfm1 = Methode_1(DOSSIER_TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur fichier ./todo\\775775.xml.gz\n",
      "La fonction Methode_2 a pris 764.44217 secondes pour s'exécuter.\n"
     ]
    }
   ],
   "source": [
    "dfm2 = Methode_2(DOSSIER_TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nature', 'ContNat', 'ArtSpe', 'CodRD', 'MtBudgPrec', 'MtPropNouv',\n",
       "       'MtPrev', 'CredOuv', 'OpBudg', 'MtSup', 'CaracSup', 'TypOpBudg',\n",
       "       'MtRARPrec', 'LibCpte', 'Operation', 'ContOp', 'MtReal', 'MtRAR3112',\n",
       "       'Fonction', 'OpeCpteTiers', 'ContFon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur fichier ./todo\\775775.xml.gz\n",
      "La fonction Methode_3 a pris 386.22054 secondes pour s'exécuter.\n"
     ]
    }
   ],
   "source": [
    "dfm3 = Methode_3(DOSSIER_TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur fichier ./fichiers/todo_xml\\775775.xml.gz\n",
      "La fonction Methode_2_test a pris 695.09354 secondes pour s'exécuter.\n"
     ]
    }
   ],
   "source": [
    "dfm21 = Methode_2_test(DOSSIER_TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nature.@V', 'ContNat.@V', 'ArtSpe.@V', 'CodRD.@V', 'MtBudgPrec.@V',\n",
       "       'MtPropNouv.@V', 'MtPrev.@V', 'CredOuv.@V', 'OpBudg.@V', 'MtSup.@V',\n",
       "       'MtSup.@Code', 'CaracSup.@V', 'CaracSup.@Code', 'TypOpBudg.@V', 'MtSup',\n",
       "       'MtRARPrec.@V', 'CaracSup', 'LibCpte.@V', 'Operation.@V', 'ContOp.@V',\n",
       "       'MtReal.@V', 'MtRAR3112.@V', 'Fonction.@V', 'OpeCpteTiers.@V',\n",
       "       'ContFon.@V'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparatif_pl = Methode_polars(DOSSIER_TODO, schema=SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nature',\n",
       " 'LibCpte',\n",
       " 'Fonction',\n",
       " 'Operation',\n",
       " 'ContNat',\n",
       " 'ArtSpe',\n",
       " 'ContFon',\n",
       " 'ContOp',\n",
       " 'CodRD',\n",
       " 'MtBudgPrec',\n",
       " 'MtRARPrec',\n",
       " 'MtPropNouv',\n",
       " 'MtPrev',\n",
       " 'CredOuv',\n",
       " 'MtReal',\n",
       " 'MtRAR3112',\n",
       " 'OpBudg',\n",
       " 'TypOpBudg',\n",
       " 'OpeCpteTiers',\n",
       " 'MtSup',\n",
       " 'CaracSup']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparatif_pl.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outpout : \n",
    "\n",
    "**Methode_1**, extraction depuis les dictionnaires : \n",
    "\n",
    "- Erreur fichier ./todo\\619027.xml.gz\n",
    "- Erreur fichier ./todo\\628857.xml.gz\n",
    "- Erreur fichier ./todo\\682109.xml.gz\n",
    "- Erreur fichier ./todo\\722795.xml.gz\n",
    "- Erreur fichier ./todo\\730073.xml.gz\n",
    "- Erreur fichier ./todo\\748147.xml.gz\n",
    "- Erreur fichier ./todo\\756300.xml.gz\n",
    "- Erreur fichier ./todo\\775775.xml.gz\n",
    "- Erreur fichier ./todo\\807134.xml.gz\n",
    "- Erreur fichier ./todo\\809162.xml.gz\n",
    "- Erreur fichier ./todo\\809290.xml.gz\n",
    "- Erreur fichier ./todo\\819789.xml.gz\n",
    "- Erreur fichier ./todo\\821461.xml.gz\n",
    "- Erreur fichier ./todo\\838663.xml.gz\n",
    "\n",
    "- La fonction Methode_1 a pris **341.08701** secondes pour s'exécuter.\n",
    "\n",
    "\n",
    "\n",
    "**Methode_2**, DataFrame : \n",
    "\n",
    "- Erreur fichier ./todo\\775775.xml.gz\n",
    "\n",
    "- La fonction Methode_2 a pris **414.56070** secondes pour s'exécuter.\n",
    "\n",
    "\n",
    "**Methode_3**, json_normalize : \n",
    "\n",
    "- Erreur fichier ./todo\\775775.xml.gz\n",
    "\n",
    "- La fonction Methode_3 a pris **386.22054** secondes pour s'exécuter.\n",
    "\n",
    "\n",
    "**Methode Polars** : \n",
    "\n",
    "- Erreur fichier ./todo\\619027.xml.gz\n",
    "- Erreur fichier ./todo\\628857.xml.gz\n",
    "- Erreur fichier ./todo\\682109.xml.gz\n",
    "- Erreur fichier ./todo\\722795.xml.gz\n",
    "- Erreur fichier ./todo\\730073.xml.gz\n",
    "- Erreur fichier ./todo\\748147.xml.gz\n",
    "- Erreur fichier ./todo\\756300.xml.gz\n",
    "- Erreur fichier ./todo\\775775.xml.gz\n",
    "- Erreur fichier ./todo\\807134.xml.gz\n",
    "- Erreur fichier ./todo\\809162.xml.gz\n",
    "- Erreur fichier ./todo\\809290.xml.gz\n",
    "- Erreur fichier ./todo\\819789.xml.gz\n",
    "- Erreur fichier ./todo\\821461.xml.gz\n",
    "- Erreur fichier ./todo\\838663.xml.gz\n",
    "\n",
    "- La fonction Methode_polars a pris **366.51400** secondes pour s'exécuter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultats sur 20 000 fichiers, pour l'extract des lignes budgetaires : \n",
    "\n",
    "- Methode extract depuis dict : 341.08701 sec, 14 erreurs \n",
    "- Methode DataFrame : 414.56070 sec, 1 erreur\n",
    "- Methode json : 386.22054 sec, 1 erreur\n",
    "- Methode Polars : 366.51400 sec, 14 erreurs \n",
    "\n",
    "Une erreure commune parmi les 4 méthode, sur le fichier 775775, il s'avère qu'il est impossible à ouvrir car l'archive est endommagée. \n",
    "\n",
    "La méthode Json est plus rapide sur le traitement, notamment car elle n'a pas besoin de nettoyer les @V dans les données, les @V n'apparaissent que sur les libelles des colonnes, cependant la méthode json_normalize traite les Carac Sup et Mt Sup de façon particulière, les rendants inexploitables. Ce gain de temps sera donc perdu lorsque l'on voudra utiliser ces informations. \n",
    "\n",
    "La méthode DataFrame elle, considère Mtsup et CaracSup comme des colonnes composées de listes de dictionnaires / de dictionnaires, les rendant exploitables plus tard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MtSup et CaracSup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dfm2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    "for col in dft.columns : \n",
    " if col in ['MtSup', 'CaracSup'] : \n",
    "  continue \n",
    " else :\n",
    "  dft[col] = dft[col].apply(nettoyage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2 = dfm2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_a_exclure = ['MtSup', 'CaracSup']\n",
    "\n",
    "# Fonction de nettoyage\n",
    "def nettoyage(colonne):\n",
    "    if colonne.name not in colonnes_a_exclure:\n",
    "        return colonne.apply(lambda x: str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\"))\n",
    "    else:\n",
    "        return colonne\n",
    "\n",
    "# Appliquer la fonction de nettoyage à chaque colonne du DataFrame\n",
    "dft2 = dft2.apply(nettoyage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2['MtSup'] = dft2['MtSup'].apply(lambda x: str(x))\n",
    "dft2['CaracSup'] = dft2['CaracSup'].apply(lambda x: str(x))\n",
    "dft2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft2['MtSup'] = dft2['MtSup'].astype(str)\n",
    "dft2['CaracSup'] = dft2['CaracSup'].astype(str)\n",
    "dft2['MtSup'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft3 = dfm2[['Nature', 'Fonction']]\n",
    "dft3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v_enz\\AppData\\Local\\Temp\\ipykernel_11740\\254260435.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dft3[col] = dft3[col].apply(nettoyage)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    "for col in dft3.columns : \n",
    " dft3[col] = dft3[col].apply(nettoyage)\n",
    "dft3\n",
    "\n",
    "dft3['Nature'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft3.columns\n",
    "dft3_reset_index = dft3.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft3_reset_index.to_parquet('./test/renouveau/df_m2_parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transformation_mtsup_test1(lignes_budget: dict) -> dict:\n",
    " '''Grâce aux spaghettis, il y a deux types de MtSup dans les fichiers,\n",
    "       des dict et des listes de dict, permet de gérer les deux cas\n",
    " '''\n",
    " for i in lignes_budget:\n",
    "  type_mtsup = i.get('MtSup')  # Permet de connaitre le type de MtSup\n",
    "  if type_mtsup is not None:  # Vérifie si la clé 'MtSup' existe\n",
    "   if isinstance(type_mtsup, dict):\n",
    "    dict_mtsup = type_mtsup\n",
    "    i['MtSup_1_Lib'] = {'@V': dict_mtsup.get('@Code', '')}\n",
    "    i['MtSup_1_Val'] = {'@V': dict_mtsup.get('@V', '')}\n",
    "   elif isinstance(type_mtsup, list):\n",
    "    dict_mtsup = i['MtSup']\n",
    "    if isinstance(dict_mtsup, dict):  # Vérifie si c'est un dict dans la liste\n",
    "     mtsup_propre = {\n",
    "                        'MtSup_1_Lib': {'@V': dict_mtsup.get('@Code', '')},\n",
    "                        'MtSup_1_Val': {'@V': dict_mtsup.get('@V', '')}\n",
    "                    }\n",
    "    else:\n",
    "     mtsup_propre = {}\n",
    "     for z, entry in enumerate(dict_mtsup, start=1):\n",
    "      code = f'MtSup_{z}_Lib'\n",
    "      valeur = f'MtSup_{z}_Val'\n",
    "      mtsup_propre[code] = entry.get('@Code', '')\n",
    "      mtsup_propre[valeur] = entry.get('@V', '')\n",
    "      i.update(mtsup_propre)\n",
    "                \n",
    "    return lignes_budget\n",
    "   \n",
    "def _transformation_mtsup_original(lignes_budget: dict) -> dict:\n",
    " '''Grâce aux spaghettis, il y a deux types de MtSup dans les fichiers,\n",
    "       des dict et des listes de dict, permet de gérer les deux cas\n",
    "    '''\n",
    " for i in lignes_budget:\n",
    "  type_mtsup = i.get('MtSup')  # Permet de connaitre le type de MtSup\n",
    "  if type_mtsup is not None:  # Vérifie si la clé 'MtSup' existe\n",
    "    if isinstance(type_mtsup, dict):\n",
    "      dict_mtsup = type_mtsup\n",
    "      i['MtSup_1_Lib'] = {'@V': dict_mtsup.get('@Code', '')}\n",
    "      i['MtSup_1_Val'] = {'@V': dict_mtsup.get('@V', '')}\n",
    "    elif isinstance(type_mtsup, list):\n",
    "      dict_mtsup = i['MtSup']\n",
    "      mtsup_propre = {}\n",
    "      for z, entry in enumerate(dict_mtsup, start=1):\n",
    "        code = f'MtSup_{z}_Lib'\n",
    "        valeur = f'MtSup_{z}_Val'\n",
    "        mtsup_propre[code] = entry.get('@Code', '')\n",
    "        mtsup_propre[valeur] = entry.get('@V', '')\n",
    "        i.update(mtsup_propre)\n",
    "        \n",
    " return lignes_budget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de la verif sur le fichier parquet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Methode Duckdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_id_fichier(chemin_parquet) :\n",
    " conduck = duckdb.connect(database=':memory:', read_only=False)\n",
    " docubudg_t = conduck.read_parquet(chemin_parquet)\n",
    " requete_duckdb = ''' \n",
    " SELECT\n",
    "    DISTINCT Id_Fichier\n",
    " FROM \n",
    "    docubudg_t\n",
    " '''\n",
    " result_requete= conduck.execute(requete_duckdb).fetchdf()\n",
    " liste_id = result_requete['Id_Fichier'].to_list()\n",
    " conduck.close()\n",
    " return liste_id\n",
    "\n",
    "\n",
    "def _isolement_id(fichier) : \n",
    " '''Extrait l'id du nom du fichier pour la liste comprehension de securité\n",
    "\n",
    " ATTENTION, le premier split / va changer si on l'applique sur du minio '''\n",
    " val_id_fichier_source = fichier.split(\"\\\\\")[-1].split('.')[0]\n",
    " if '-' in val_id_fichier_source : \n",
    "  val_id_fichier = val_id_fichier_source.split('-')[1]\n",
    " else : \n",
    "  val_id_fichier= val_id_fichier_source\n",
    " return val_id_fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timtim\n",
    "def Methode_2_1(chemin, chemin_verif) : \n",
    " liste_id = recherche_id_fichier(chemin_verif)\n",
    " liste_df = []\n",
    " for fichier in glob.glob(os.path.join(chemin, \"*.gz\")) : \n",
    "  id_fichier = _isolement_id(fichier)\n",
    "  #Fichier non pre existant dans la db / parquet\n",
    "  if id_fichier in liste_id :\n",
    "   pass \n",
    "  else : \n",
    "   try : \n",
    "     fichier_parse = parse_fichier(fichier)\n",
    "     metadonnees = fichier_parse['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    "     donnes_budget = fichier_parse['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "     metadonnees['Id_Fichier'] = {'@V' : id_fichier}\n",
    "     for i in donnes_budget : \n",
    "      i.update(metadonnees)\n",
    "     def_2_1 = pd.DataFrame(donnes_budget)\n",
    "     nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    "     for col in def_2_1.columns : \n",
    "      def_2_1[col] = def_2_1[col].apply(nettoyage)\n",
    "     liste_df.append(def_2_1)\n",
    "   except Exception as e : \n",
    "     print(f'Erreur fichier {fichier}')\n",
    "     continue\n",
    " df_2_1 = pd.concat(liste_df)\n",
    " df_2_1.to_parquet('parquet_renouveau', compression= 'gzip')\n",
    " return df_2_1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timtim\n",
    "def Extraction_xml_to_parquet(chemin) : \n",
    " ''' Traite les XML et les envoies sous format parquet, pas encore de nettoyage'''\n",
    " for fichier in glob.glob(os.path.join(chemin, \"*.gz\")) : \n",
    "  try : \n",
    "   id_fichier = _isolement_id(fichier)\n",
    "   dico = parse_fichier(fichier)\n",
    "   metadonnees = dico['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    "   metadonnees['Id_Fichier'] = {'@V' : id_fichier}\n",
    "   docbase = dico['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "   for i in docbase : \n",
    "      i.update(metadonnees)\n",
    "   df_methode_2 = pd.DataFrame(docbase)\n",
    "   df_methode_2['MtSup'] = df_methode_2['MtSup'].astype(str)\n",
    "   df_methode_2['CaracSup'] = df_methode_2['CaracSup'].astype(str)\n",
    "   df_methode_2 = df_methode_2.reset_index(drop=True)\n",
    "   df_methode_2.to_parquet(f'./fichiers/todo_parquet/{id_fichier}', engine='pyarrow')\n",
    "   #shutil.move(fichier, './fichiers/done_xml/')\n",
    "  except Exception as e : \n",
    "    print(f'Erreur fichier {fichier}, extraction impossible')\n",
    "    #shutil.move(fichier, './fichiers/todo_xml/error/')\n",
    "    print(e)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./fichiers/todo_xml/test1000/t500/612019.xml.gz'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemin_test_xml_500 = './fichiers/todo_xml/test1000/t500/'\n",
    "chemin_test_xml_solo = './fichiers/todo_xml/test1000/t500/612019.xml.gz'\n",
    "chemin_test_xml_solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur fichier ./fichiers/todo_xml/test1000/t500\\612023.xml.gz, extraction impossible\n",
      "'MtSup'\n",
      "La fonction Extraction_xml_to_parquet a pris 0.02500 secondes pour s'exécuter.\n"
     ]
    }
   ],
   "source": [
    "Extraction_xml_to_parquet(chemin_test_xml_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612019\n",
      "612023\n",
      "612027\n",
      "612030\n",
      "612038\n",
      "612050\n",
      "612057\n",
      "612058\n",
      "612069\n",
      "612078\n",
      "612117\n",
      "612127\n",
      "612128\n",
      "612131\n",
      "612136\n",
      "612151\n",
      "612159\n",
      "612160\n",
      "612172\n",
      "612180\n",
      "612188\n",
      "612192\n",
      "612220\n",
      "612221\n",
      "612223\n",
      "612240\n",
      "612241\n",
      "612245\n",
      "612262\n",
      "612264\n",
      "612266\n",
      "612269\n",
      "612271\n",
      "612289\n",
      "612292\n",
      "612295\n",
      "612328\n",
      "612339\n",
      "612347\n",
      "612350\n",
      "612365\n",
      "612370\n",
      "612376\n",
      "612406\n",
      "612415\n",
      "612420\n",
      "612424\n",
      "612425\n",
      "612450\n",
      "612458\n",
      "612482\n",
      "612492\n",
      "612499\n",
      "612527\n",
      "612529\n",
      "612546\n",
      "612547\n",
      "612560\n",
      "612561\n",
      "612563\n",
      "612598\n",
      "612621\n",
      "612633\n",
      "612652\n",
      "612661\n",
      "612664\n",
      "612675\n",
      "612678\n",
      "612680\n",
      "612690\n",
      "612711\n",
      "612733\n",
      "612755\n",
      "612760\n",
      "612780\n",
      "612787\n",
      "612804\n",
      "612821\n",
      "612826\n",
      "612829\n",
      "612847\n",
      "612876\n",
      "612883\n",
      "612896\n",
      "612902\n",
      "612908\n",
      "612914\n",
      "612923\n",
      "612943\n",
      "612984\n",
      "612987\n",
      "612991\n",
      "612998\n",
      "613002\n",
      "613011\n",
      "613012\n",
      "613025\n",
      "613029\n",
      "613032\n",
      "613068\n",
      "613074\n",
      "613088\n",
      "613113\n",
      "613124\n",
      "613134\n",
      "613135\n",
      "613143\n",
      "613145\n",
      "613152\n",
      "613182\n",
      "613186\n",
      "613189\n",
      "613217\n",
      "613234\n",
      "613235\n",
      "613254\n",
      "613272\n",
      "613291\n",
      "613298\n",
      "613309\n",
      "613320\n",
      "613339\n",
      "613345\n",
      "613362\n",
      "613370\n",
      "613379\n",
      "613385\n",
      "613386\n",
      "613407\n",
      "613408\n",
      "613410\n",
      "613413\n",
      "613437\n",
      "613467\n",
      "613472\n",
      "613483\n",
      "613485\n",
      "613510\n",
      "613517\n",
      "613524\n",
      "613526\n",
      "613535\n",
      "613562\n",
      "613602\n",
      "613605\n",
      "613617\n",
      "613626\n",
      "613633\n",
      "613664\n",
      "613667\n",
      "613669\n",
      "613672\n",
      "613698\n",
      "613730\n",
      "613733\n",
      "613750\n",
      "613769\n",
      "613781\n",
      "613784\n",
      "613804\n",
      "613814\n",
      "613819\n",
      "613827\n",
      "613837\n",
      "613853\n",
      "613854\n",
      "613859\n",
      "613879\n",
      "613901\n",
      "613918\n",
      "613919\n",
      "613922\n",
      "613926\n",
      "613933\n",
      "613938\n",
      "613947\n",
      "613950\n",
      "613953\n",
      "613958\n",
      "613960\n",
      "613968\n",
      "613985\n",
      "613992\n",
      "613994\n",
      "614008\n",
      "614009\n",
      "614034\n",
      "614084\n",
      "614085\n",
      "614087\n",
      "614092\n",
      "614093\n",
      "614107\n",
      "614108\n",
      "614126\n",
      "614133\n",
      "614157\n",
      "614161\n",
      "614162\n",
      "614174\n",
      "614190\n",
      "614206\n",
      "614218\n",
      "614231\n",
      "614233\n",
      "614238\n",
      "614244\n",
      "614254\n",
      "614263\n",
      "614264\n",
      "614271\n",
      "614285\n",
      "614297\n",
      "614299\n",
      "614308\n",
      "614315\n",
      "614338\n",
      "614349\n",
      "614350\n",
      "614354\n",
      "614355\n",
      "614362\n",
      "614384\n",
      "614387\n",
      "614400\n",
      "614405\n",
      "614411\n",
      "614434\n",
      "614451\n",
      "614454\n",
      "614461\n",
      "614462\n",
      "614463\n",
      "614478\n",
      "614484\n",
      "614498\n",
      "614503\n",
      "614505\n",
      "614515\n",
      "614517\n",
      "614522\n",
      "614551\n",
      "614552\n",
      "614556\n",
      "614557\n",
      "614561\n",
      "614572\n",
      "614574\n",
      "614586\n",
      "614599\n",
      "614604\n",
      "614651\n",
      "614654\n",
      "614656\n",
      "614660\n",
      "614663\n",
      "614666\n",
      "614677\n",
      "614685\n",
      "614687\n",
      "614737\n",
      "614740\n",
      "614744\n",
      "614751\n",
      "614767\n",
      "614769\n",
      "614772\n",
      "614775\n",
      "614802\n",
      "614819\n",
      "614826\n",
      "614834\n",
      "614835\n",
      "614843\n",
      "614844\n",
      "614891\n",
      "614916\n",
      "614929\n",
      "614959\n",
      "614963\n",
      "614964\n",
      "614972\n",
      "614982\n",
      "614995\n",
      "615002\n",
      "615018\n",
      "615019\n",
      "615037\n",
      "615043\n",
      "615045\n",
      "615050\n",
      "615055\n",
      "615066\n",
      "615073\n",
      "615087\n",
      "615101\n",
      "615107\n",
      "615111\n",
      "615127\n",
      "615128\n",
      "615145\n",
      "615154\n",
      "615167\n",
      "615174\n",
      "615188\n",
      "615193\n",
      "615204\n",
      "615225\n",
      "615248\n",
      "615273\n",
      "615284\n",
      "615289\n",
      "615300\n",
      "615302\n",
      "615306\n",
      "615332\n",
      "615341\n",
      "615352\n",
      "615355\n",
      "615379\n",
      "615389\n",
      "615396\n",
      "615408\n",
      "615412\n",
      "615414\n",
      "615417\n",
      "615433\n",
      "615434\n",
      "615439\n",
      "615450\n",
      "615459\n",
      "615473\n",
      "615493\n",
      "615495\n",
      "615506\n",
      "615536\n",
      "615546\n",
      "615552\n",
      "615554\n",
      "615577\n",
      "615588\n",
      "615600\n",
      "615660\n",
      "615667\n",
      "615694\n",
      "615700\n",
      "615710\n",
      "615726\n",
      "615738\n",
      "615740\n",
      "615742\n",
      "615746\n",
      "615753\n",
      "615759\n",
      "615767\n",
      "615776\n",
      "615783\n",
      "615807\n",
      "615827\n",
      "615881\n",
      "615882\n",
      "615890\n",
      "615943\n",
      "616000\n",
      "616008\n",
      "616015\n",
      "616030\n",
      "616039\n",
      "616041\n",
      "616049\n",
      "616055\n",
      "616078\n",
      "616091\n",
      "616094\n",
      "616101\n",
      "616103\n",
      "616124\n",
      "616125\n",
      "616146\n",
      "616148\n",
      "616149\n",
      "616154\n",
      "616169\n",
      "616179\n",
      "616216\n",
      "616230\n",
      "616238\n",
      "616241\n",
      "616243\n",
      "616260\n",
      "616273\n",
      "616276\n",
      "616287\n",
      "616288\n",
      "616289\n",
      "616296\n",
      "616329\n",
      "616355\n",
      "616362\n",
      "616363\n",
      "616379\n",
      "616436\n",
      "616445\n",
      "616447\n",
      "616448\n",
      "616449\n",
      "616454\n",
      "616462\n",
      "616473\n",
      "616475\n",
      "616476\n",
      "616477\n",
      "616482\n",
      "616505\n",
      "616517\n",
      "616521\n",
      "616537\n",
      "616539\n",
      "616549\n",
      "616564\n",
      "616567\n",
      "616581\n",
      "616601\n",
      "616602\n",
      "616605\n",
      "616614\n",
      "616619\n",
      "616635\n",
      "616640\n",
      "616652\n",
      "616655\n",
      "616659\n",
      "616660\n",
      "616666\n",
      "616680\n",
      "616718\n",
      "616731\n",
      "616735\n",
      "616738\n",
      "616758\n",
      "616768\n",
      "616790\n",
      "616794\n",
      "616796\n",
      "616802\n",
      "616818\n",
      "616825\n",
      "616844\n",
      "616849\n",
      "616885\n",
      "616916\n",
      "616930\n",
      "616932\n",
      "616943\n",
      "616946\n",
      "616948\n",
      "616973\n",
      "616976\n",
      "616997\n",
      "617029\n",
      "617034\n",
      "617084\n",
      "617092\n",
      "617093\n",
      "617095\n",
      "617107\n",
      "617116\n",
      "617144\n",
      "617151\n",
      "617158\n",
      "617166\n",
      "617175\n",
      "617188\n",
      "617199\n",
      "617205\n",
      "617210\n",
      "617216\n",
      "617217\n",
      "617227\n",
      "617230\n",
      "617254\n",
      "617262\n",
      "617267\n",
      "617281\n",
      "617324\n",
      "617370\n",
      "617387\n",
      "617410\n",
      "617421\n",
      "617424\n",
      "617429\n",
      "617442\n",
      "617444\n",
      "617446\n",
      "617488\n",
      "617494\n",
      "617504\n",
      "617516\n",
      "617536\n"
     ]
    }
   ],
   "source": [
    "for ss in glob.glob(os.path.join(chemin_test_xml_500, \"*.gz\")) : \n",
    " id_ss = _isolement_id(ss)\n",
    " print(id_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_fichier_b = _isolement_id(chemin_test_xml_solo)\n",
    "dico_b = parse_fichier(chemin_test_xml_solo)\n",
    "metadonnees_b = dico_b['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    "metadonnees_b['Id_Fichier'] = {'@V' : id_fichier_b}\n",
    "docbase_b = dico_b['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "for i in docbase_b : \n",
    " i.update(metadonnees_b)\n",
    "df_methode_2_b = pd.DataFrame(docbase_b)\n",
    "df_methode_2_b['MtSup'] = df_methode_2_b['MtSup'].astype(str)\n",
    "df_methode_2_b['CaracSup'] = df_methode_2_b['CaracSup'].astype(str)\n",
    "df_methode_2_b = df_methode_2_b.reset_index(drop=True)\n",
    "df_methode_2_b.to_parquet(f'./fichiers/todo_parquet/{id_fichier_b}', engine='pyarrow')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nature', 'ContNat', 'ArtSpe', 'CodRD', 'MtBudgPrec', 'MtPropNouv',\n",
       "       'MtPrev', 'CredOuv', 'OpBudg', 'MtSup', 'CaracSup', 'DteStr',\n",
       "       'LibellePoste', 'IdPost', 'LibelleColl', 'IdColl', 'NatCEPL',\n",
       "       'Departement', 'Id_Fichier', 'TypOpBudg', 'MtRARPrec', 'LibCpte',\n",
       "       'Operation', 'ContOp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'@V': '24'}\n",
       "1      {'@V': '24'}\n",
       "2      {'@V': '24'}\n",
       "3      {'@V': '24'}\n",
       "4      {'@V': '24'}\n",
       "           ...     \n",
       "177    {'@V': '24'}\n",
       "178    {'@V': '24'}\n",
       "179    {'@V': '24'}\n",
       "180    {'@V': '24'}\n",
       "181    {'@V': '24'}\n",
       "Name: Departement, Length: 182, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_methode_2_a.to_parquet(f'./fichiers/todo_parquet/{id_fichier_a}', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./fichiers/done_xml/612013.xml.gz'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'612013.xml.gz'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
