{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "import gzip \n",
    "import pandas as pd \n",
    "import xmltodict\n",
    "import glob\n",
    "import os \n",
    "import time \n",
    "import polars as pl \n",
    "import duckdb\n",
    "import shutil \n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parquet_schema\n",
    "\n",
    "schema_parquet = pa.schema([\n",
    "    ('Id_Fichier', pa.string()), #int64\n",
    "    ('IdColl', pa.string()),\n",
    "    ('DteStr', pa.string()), #string\n",
    "    ('LibellePoste', pa.string()),\n",
    "    ('IdPost', pa.string()),\n",
    "    ('TypOpBudg', pa.string()), #des 2 et des 1\n",
    "    ('OpeCpteTiers', pa.string()),\n",
    "    ('NatCEPL', pa.string()),\n",
    "    ('Departement', pa.string()), #On oublie pas les 2A,\n",
    "    ('NatDec', pa.string()), #A terme, sera un pa.dicitonnary\n",
    "    ('Exer', pa.float32()), #int16\n",
    "    ('ProjetBudget', pa.string()), #bool mais à verif \n",
    "    ('NatVote', pa.string()), #dico aussi\n",
    "    ('OpeEquip', pa.string()), #necessite recherche\n",
    "    ('VoteFormelChap', pa.string()), #bool mais à verif \n",
    "    ('TypProv', pa.string()), #int ? \n",
    "    ('BudgPrec', pa.string()), #int ?\n",
    "    ('ReprRes', pa.string()), #int ?\n",
    "    ('NatFonc', pa.string()), #int ?\n",
    "    ('CodTypBud', pa.string()),\n",
    "    ('LibelleEtabPal', pa.string()),\n",
    "    ('IdEtabPal', pa.string()),\n",
    "    ('LibelleEtab', pa.string()),\n",
    "    ('IdEtab', pa.string()),\n",
    "    ('CodColl', pa.string()),\n",
    "    ('CodInseeColl', pa.string()),\n",
    "    ('CodBud', pa.string()),\n",
    "    ('Nomenclature', pa.string()),\n",
    "    ('Nature', pa.string()),\n",
    "    ('Fonction', pa.string()),\n",
    "    ('LibCpte', pa.string()),\n",
    "    ('ContNat', pa.string()),\n",
    "    ('ArtSpe', pa.string()), #Doit être corrigé en bool,\n",
    "    ('ContFon', pa.string()),\n",
    "    ('CodRD', pa.string()), #Val D ou R,\n",
    "    ('MtBudgPrec', pa.float32()), #float32 #nullable = True\n",
    "    ('MtRARPrec', pa.float32()), #float32\n",
    "    ('MtPropNouv', pa.float32()), #float32\n",
    "    ('MtPrev', pa.float32()), #float32\n",
    "    ('CredOuv', pa.float32()), #int32\n",
    "    ('MtReal', pa.float32()), #float32\n",
    "    ('MtRAR3112', pa.float32()), #float32\n",
    "    ('OpBudg', pa.string()),\n",
    "    ('MtSup', pa.string()),\n",
    "    ('CaracSup', pa.string()),\n",
    "        ('BudgetHorsRAR', pa.string()),\n",
    "        ('ICNE', pa.string()),\n",
    "        ('ICNEPrec', pa.string()),\n",
    "        ('APVote', pa.string()),\n",
    "        ('ProdChaRat', pa.string()),\n",
    "        ('RARPrec', pa.string()),\n",
    "        ('ProgAutoLib', pa.string()),\n",
    "        ('ProgAutoNum', pa.string()),\n",
    "        ('MtOpeCumul', pa.string()),\n",
    "        ('Brut', pa.string()),\n",
    "        ('Comp', pa.string()),\n",
    "        ('Net', pa.string()),\n",
    "        ('ChapSpe', pa.string()),\n",
    "        ('MtOpeInfo', pa.string()),\n",
    "        ('TypOpe', pa.string()),\n",
    "        ('MtSup_8_Lib', pa.string()),\n",
    "        ('MtSup_8_Val', pa.string()),\n",
    "        ('MtSup_9_Lib', pa.string()),\n",
    "        ('MtSup_9_Val', pa.string()),\n",
    "        ('MtSup_10_Lib', pa.string()),\n",
    "        ('MtSup_10_Val', pa.string()), #10\n",
    "        ('CaracSup_1_Lib', pa.string()),\n",
    "        ('CaracSup_1_Val', pa.string()),\n",
    "        ('CaracSup_2_Lib', pa.string()),\n",
    "        ('CaracSup_2_Val', pa.string()),\n",
    "        ('CaracSup_3_Lib', pa.string()),\n",
    "        ('CaracSup_3_Val', pa.string()),\n",
    "        ('CaracSup_4_Lib', pa.string()),\n",
    "        ('CaracSup_4_Val', pa.string()),\n",
    "        ('CaracSup_5_Lib', pa.string()),\n",
    "        ('CaracSup_5_Val', pa.string()),\n",
    "        ('CaracSup_6_Lib', pa.string()),\n",
    "        ('CaracSup_6_Val', pa.string()),\n",
    "        ('CaracSup_7_Lib', pa.string()), #7\n",
    "        ('CaracSup_7_Val', pa.string()),\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonctions de base\n",
    "\n",
    "def _recherche_id_dans_parquet(chemin_parquet_db):\n",
    " \n",
    " conduck = duckdb.connect(database=':memory:', read_only=False)\n",
    " source_duck = conduck.read_parquet(f'{chemin_parquet_db}')\n",
    " requete = conduck.execute(''' \n",
    "    SELECT DISTINCT Id_Fichier \n",
    "    FROM source_duck''')\n",
    " ligne_sql_int = [int(x[0]) for x in requete.fetchall()]\n",
    " conduck.close()\n",
    " return ligne_sql_int\n",
    "\n",
    "def parse_fichier(chemin) : \n",
    " '''Ouvre et parse le fichier gzip'''\n",
    " with gzip.open(chemin, 'rb') as fichier_ouvert : \n",
    "  fichier_xml_gzip = fichier_ouvert.read()\n",
    "  fichier_xml = fichier_xml_gzip.decode('latin-1')\n",
    "  fichier_dict = xmltodict.parse(fichier_xml)\n",
    " return fichier_dict\n",
    "\n",
    "def recherche_id_fichier(chemin_parquet) :\n",
    " ''' Pas encore utilisée, permet de récupérer les ID dans le parquet contenant les \n",
    " données déjà traitées '''\n",
    " conduck = duckdb.connect(database=':memory:', read_only=False)\n",
    " docubudg_t = conduck.read_parquet(chemin_parquet)\n",
    " requete_duckdb = ''' \n",
    " SELECT\n",
    "    DISTINCT Id_Fichier\n",
    " FROM \n",
    "    docubudg_t\n",
    " '''\n",
    " result_requete= conduck.execute(requete_duckdb).fetchdf()\n",
    " liste_id = result_requete['Id_Fichier'].to_list()\n",
    " conduck.close()\n",
    " return liste_id\n",
    "\n",
    "def _isolement_id(fichier) : \n",
    " '''Extrait l'id du nom du fichier pour la liste comprehension de securité\n",
    "\n",
    " ATTENTION, le premier split / va changer si on l'applique sur du minio '''\n",
    " val_id_fichier_source = fichier.split(\"\\\\\")[-1].split('.')[0]\n",
    " if '-' in val_id_fichier_source : \n",
    "  val_id_fichier = val_id_fichier_source.split('-')[1]\n",
    " else : \n",
    "  val_id_fichier= val_id_fichier_source\n",
    " return val_id_fichier\n",
    "\n",
    "def nettoyage_V(dataframe : pd.DataFrame) -> pd.DataFrame :\n",
    " ''' Permet de supprimer les @V des colonnes à l'exception de MtSup et CaracSup'''\n",
    "\n",
    " nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    " for col in dataframe.columns : \n",
    "  if col in ['MtSup', 'CaracSup'] : \n",
    "   dataframe[col] = dataframe[col].astype(str) \n",
    "  else :\n",
    "   dataframe[col] = dataframe[col].apply(nettoyage)\n",
    " dataframe_propre = dataframe.reset_index(drop=True)\n",
    " return dataframe_propre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travail_mtsup_ligne(ligne_budg) :\n",
    " type_m = ligne_budg.get('MtSup')\n",
    " if type_m is None : \n",
    "  pass \n",
    " else : \n",
    "  if isinstance(type_m, dict) : \n",
    "   ligne_budg[type_m.get('@Code', '')] = {'@V' : type_m.get('@V', '')}\n",
    "  elif isinstance(type_m, list) :\n",
    "    for z in type_m : #z c'est un dict contenant un V et un Code \n",
    "      ligne_budg[z.get('@Code', '')] = {'@V' : z.get('@V', '')}\n",
    " return ligne_budg\n",
    "\n",
    "def travail_caracsup_ligne(ligne_budg) : \n",
    " type_c = ligne_budg.get('CaracSup')\n",
    " if type_c is None : \n",
    "  pass \n",
    " else : \n",
    "  if isinstance(type_c, dict) : \n",
    "   ligne_budg[type_c.get('@Code', '')] = {'@V' : type_c.get('@V', '')}\n",
    "  elif isinstance(type_c, list) : \n",
    "   for ii in type_c : \n",
    "    ligne_budg[ii.get('@Code', '')] = {'@V' : ii.get('@V', '')}\n",
    " return ligne_budg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_1_v3(chemin_xml_entree, chemin_parquet_verif, chemin_sortie) : \n",
    " ''' La V2 traite en plus :\n",
    "  - F Le cas où il n'y a qu'une seule ligne budget (pour caracsup et mtsup).\n",
    "  - F Rentre au propre MtSup Et CaracSup\n",
    "  - F Ajoute des chemins que l'on peut choisir\n",
    "  - F Ajoute une verification depuis un plus grand parquet, ça pourra se faire via une db plus tôt, quand on en aura une\n",
    "  - F Sert un café robusta pas fou mais buvable\n",
    "  - F Ajoute de nouvelles métadonnées, dont l'année d'exercice, la nature de vote, le siret d'etab parfois different du premier siret etc. \n",
    "  - En cours, Fait le schema à cette étape pour éviter tout soucis après \n",
    " '''\n",
    "\n",
    " chemin_xml_entree_glob = glob.glob(os.path.join(chemin_xml_entree, \"*.gz\"))\n",
    " liste_verif_parquet = _recherche_id_dans_parquet(chemin_parquet_db= chemin_parquet_verif)\n",
    " liste_fichiers_safe = [chemin_fichier for chemin_fichier in chemin_xml_entree_glob if int(_isolement_id(chemin_fichier)) not in liste_verif_parquet]\n",
    " for fichier in liste_fichiers_safe : \n",
    "  try : \n",
    "   id_fichier = _isolement_id(fichier)\n",
    "   dico = parse_fichier(fichier)\n",
    "   metadonnees = dico['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    "   metadonnees.update(dico['DocumentBudgetaire']['Budget']['BlocBudget'])\n",
    "   metadonnees.update(dico['DocumentBudgetaire']['Budget']['EnTeteBudget'])\n",
    "   metadonnees['Id_Fichier'] = {'@V' : id_fichier}\n",
    "   docbase = dico['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "   if isinstance(docbase, list):\n",
    "    for i in docbase : \n",
    "      i.update(metadonnees)\n",
    "      i = travail_mtsup_ligne(i)\n",
    "      i = travail_caracsup_ligne(i)\n",
    "   elif isinstance(docbase, dict) : \n",
    "    docbase.update(metadonnees)\n",
    "    docbase = travail_mtsup_ligne(docbase)\n",
    "    docbase = travail_caracsup_ligne(docbase)\n",
    "   df_base = pd.DataFrame(docbase)\n",
    "   df_propre = nettoyage_V(df_base)\n",
    "   df_propre.to_parquet(f'{chemin_sortie}{id_fichier}_parquet', engine='pyarrow')\n",
    "   #shutil.move(fichier, './fichiers/done_xml/')\n",
    "  except Exception as e : \n",
    "    print(f'Erreur fichier {fichier}, extraction impossible')\n",
    "    #shutil.move(fichier, './fichiers/todo_xml/error/')\n",
    "    print(f'Erreur complète : {repr(e)}')\n",
    "    traceback.print_exc()\n",
    "    continue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test complet sur 20k fichiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur fichier .././fichiers/todo_xml\\775775.xml.gz, extraction impossible\n",
      "Erreur complète : ExpatError('no element found: line 1, column 0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\v_enz\\AppData\\Local\\Temp\\ipykernel_21072\\320273135.py\", line 18, in task_1_v3\n",
      "    dico = parse_fichier(fichier)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\v_enz\\AppData\\Local\\Temp\\ipykernel_21072\\1877147927.py\", line 19, in parse_fichier\n",
      "    fichier_dict = xmltodict.parse(fichier_xml)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\python\\Lib\\site-packages\\xmltodict.py\", line 378, in parse\n",
      "    parser.Parse(xml_input, True)\n",
      "xml.parsers.expat.ExpatError: no element found: line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "task_1_v3('.././fichiers/todo_xml/', '.././fichiers/parquet_vide_verif', '.././fichiers/todo_parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2(dossier_entree, chemin_parquet_global, schema_cust) :\n",
    " liste_parquet_t = []\n",
    " for parquet in glob.glob(os.path.join(dossier_entree, \"*\")) : \n",
    "  liste_parquet_t.append(parquet)\n",
    " with pq.ParquetWriter(f\"{chemin_parquet_global}.parquet\", schema=schema_cust) as writer:\n",
    "    for file in liste_parquet_t:\n",
    "        table = pq.read_table(file, schema=schema_cust)\n",
    "        writer.write_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2('.././fichiers/todo_parquet/', './parquet_v3', schema_cust=schema_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Exer\n",
       "0  2021.0\n",
       "1  2020.0\n",
       "2     NaN\n",
       "3  2022.0\n",
       "4  2018.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conduck = duckdb.connect(database=':memory:', read_only=False)\n",
    "source_duck = conduck.read_parquet('./parquet_v3.parquet')\n",
    "\n",
    "requete_1 = ''' \n",
    "    SELECT DISTINCT Exer\n",
    "    FROM source_duck\n",
    "    '''\n",
    "df_result1 = conduck.execute(requete_1).fetchdf()\n",
    "#conduck.close()\n",
    "print(df_result1.shape)\n",
    "df_result1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_Fichier</th>\n",
       "      <th>Exer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id_Fichier  Exer\n",
       "0        nan   NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requete_exer_nan = '''\n",
    "    SELECT DISTINCT Id_Fichier, Exer\n",
    "    FROM source_duck\n",
    "    WHERE Exer NOT IN ('2021.0','2020.0', '2022.0', '2018.0', '2019.0')\n",
    "'''\n",
    "df__exer_nan = conduck.execute(requete_exer_nan).fetchdf()\n",
    "#conduck.close()\n",
    "print(df__exer_nan.shape)\n",
    "df__exer_nan.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
