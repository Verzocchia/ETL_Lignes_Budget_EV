{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gzip \n",
    "import glob \n",
    "import xmltodict \n",
    "import pandas as pd \n",
    "import json \n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import MetaData, text, String, Float, Integer, Boolean, ForeignKey, Select, func, Table\n",
    "from sqlalchemy import JSON\n",
    "from sqlalchemy.orm import sessionmaker, DeclarativeBase, Mapped, mapped_column, relationship\n",
    "from typing import Optional, List \n",
    "\n",
    "engine = sqlalchemy.create_engine('postgresql://verzochia:verzochia@localhost:5432/db_v1')\n",
    "conn = engine.connect()\n",
    "metadata = MetaData()\n",
    "\n",
    "LIST_ANNEXES = ['DATA_AMORTISSEMENT_METHODE', 'DATA_APCP', 'DATA_AUTRE_ENGAGEMENT',\n",
    "        'DATA_CHARGE', 'DATA_CONCOURS', 'DATA_CONSOLIDATION', 'DATA_CONTRAT_COUV', \n",
    "        \"DATA_CONTRAT_COUV_REFERENCE\", \"DATA_CREDIT_BAIL\", \"DATA_DETTE\", \"DATA_EMPRUNT\", \n",
    "        \"DATA_ETAB_SERVICE\", \"DATA_FISCALITE\", \"DATA_FOND_AIDES_ECO\", \"DATA_FOND_COMM_HEBERGEMENT\", \n",
    "        \"DATA_FOND_EUROPEEN\", \"DATA_FOND_EUROPEEN_PROGRAMMATION\", \"DATA_FORMATION\", \n",
    "        \"DATA_FORMATION_PRO_JEUNES\", \"DATA_MEMBRESASA\", \"DATA_ORGANISME_ENG\", \n",
    "        \"DATA_ORGANISME_GROUP\", \"DATA_PATRIMOINE\", \"DATA_PERSONNEL\", \"DATA_PERSONNEL_SOLDE\", \n",
    "        \"DATA_PPP\", \"DATA_PRET\", \"DATA_PROVISION\", \"DATA_RECETTE_AFFECTEE\", \n",
    "        \"DATA_SERVICE_FERROVIAIRE_BUD\", \"DATA_SERVICE_FERROVIAIRE_PATRIM\", \n",
    "        \"DATA_SERVICE_FERROVIAIRE_TER\", \"DATA_SIGNATAIRE\", \"DATA_SIGNATURE\", \n",
    "        \"DATA_SOMMAIRE\", \"DATA_TIERS\", \"DATA_TRESORERIE\", \"DATA_VENTILATION\", \"DATA_FLUX_CROISES\"]\n",
    "\n",
    "def extraction_id(fichier : str) -> str : \n",
    " '''Extrait l'id du fichier, renvoie un str. '''\n",
    " val_id_fichier = fichier.split(\"/\")[-1].split('.')[0]\n",
    " return val_id_fichier\n",
    "\n",
    "def parse_fichier(chemin : str) -> dict: \n",
    " '''Ouvre et parse le fichier gzip en dictionnaire'''\n",
    " with gzip.open(chemin, 'rb') as fichier_ouvert : \n",
    "  fichier_xml_gzip = fichier_ouvert.read()\n",
    "  fichier_xml = fichier_xml_gzip.decode('latin-1')\n",
    "  fichier_dict = xmltodict.parse(fichier_xml)\n",
    " return fichier_dict\n",
    "\n",
    "def extraction_annexe(chemin_annexe : dict, dict_metadonnees : dict) -> list : \n",
    " liste_annexe = []\n",
    " for row in chemin_annexe : \n",
    "  liste_par_ligne = {}\n",
    "  for a, b in row.items() : \n",
    "   liste_par_ligne.update({a : b.get('@V')})\n",
    "   liste_par_ligne.update(dict_metadonnees)\n",
    "  liste_annexe.append(liste_par_ligne)\n",
    " return liste_annexe \n",
    "\n",
    "def extraction_donnees(chemin : dict) -> dict  : \n",
    " dict_annexe = {}\n",
    " for a, b in chemin.items() : \n",
    "   dict_annexe.update({a : b.get('@V')})\n",
    " return dict_annexe \n",
    "\n",
    "def extraction_lignes_budget_liste(chemin : dict, dict_id : dict) -> list :\n",
    " liste_budget = []\n",
    " for lignes in chemin : \n",
    "  dict_ligne = {}\n",
    "  dict_ligne.update(dict_id)\n",
    "  for a, b in lignes.items() :\n",
    "     if a not in ['MtSup', 'CaracSup'] : \n",
    "       dict_ligne.update({a : b.get('@V')}) \n",
    " \n",
    "     elif a == 'MtSup' : \n",
    "       dict_ligne.update({a : json.dumps(b)})\n",
    "       type_m = lignes.get('MtSup')\n",
    " \n",
    "       if isinstance(type_m, dict) : \n",
    "        dict_ligne.update({f\"MtSup_{type_m.get('@Code')}\" : type_m.get('@V')})\n",
    " \n",
    "       elif isinstance(type_m, list) :\n",
    "          for j in b : \n",
    "           dict_ligne.update({f\"MtSup_{j.get('@Code')}\" : j.get('@V')})\n",
    " \n",
    "     elif a == 'CaracSup' :   \n",
    "       type_c = lignes.get('CaracSup')\n",
    "       dict_ligne.update({a : json.dumps(b)})\n",
    "\n",
    "       if isinstance(type_c, dict) :\n",
    "        dict_ligne.update({f\"CaracSup_{type_c.get('@Code')}\" : type_c.get('@V')})\n",
    " \n",
    "       elif isinstance(type_c, list) : \n",
    "          for j in b : \n",
    "           dict_ligne.update({f\"CaracSup_{j.get('@Code')}\" : j.get('@V')})\n",
    "\n",
    "  liste_budget.append(dict_ligne)\n",
    " return liste_budget\n",
    "\n",
    "def extraction_budget(fichier_parse : dict , infos_doc_budgetaire : dict)  -> pd.DataFrame : \n",
    " ''' Extrait toutes les données budgetaires, y compris carac et mtsup '''\n",
    " lignes_budget = fichier_parse['DocumentBudgetaire']['Budget']['LigneBudget'] \n",
    "\n",
    " if isinstance(lignes_budget, dict) : \n",
    "  donnees_budget_prep = extraction_donnees(lignes_budget)\n",
    "  donnees_budget_prep.update(infos_doc_budgetaire)\n",
    "  donnees_budget = [donnees_budget_prep]\n",
    "\n",
    " elif isinstance(lignes_budget, list) : \n",
    "  donnees_budget = extraction_lignes_budget_liste(lignes_budget, infos_doc_budgetaire)\n",
    "\n",
    " df_budget = pd.DataFrame(donnees_budget)\n",
    " return df_budget \n",
    "\n",
    "def extraction_document_budgetaire(fichier_parse : dict, dictionnaire_id : dict) -> pd.DataFrame : \n",
    "  ''' Extrait les métadonnées du fichier pour la table document_budgetaire '''\n",
    "  blocbudget = extraction_donnees(fichier_parse['DocumentBudgetaire']['Budget']['BlocBudget'])\n",
    "  entetedocbudg = extraction_donnees(fichier_parse['DocumentBudgetaire']['EnTeteDocBudgetaire'])\n",
    "  entetebudget = extraction_donnees(fichier_parse['DocumentBudgetaire']['Budget']['EnTeteBudget'])\n",
    "  scellement = {'Date' : fichier_parse['DocumentBudgetaire']['Scellement'].get('@date'),\n",
    "                'Md5' : fichier_parse['DocumentBudgetaire']['Scellement'].get('@md5'), \n",
    "                'Sha1' : fichier_parse['DocumentBudgetaire']['Scellement'].get('@sha1')}\n",
    "\n",
    "  liste_fichier = [{**blocbudget, **entetedocbudg, **entetebudget, **scellement, **dictionnaire_id}]\n",
    "  df_doc_budgetaire = pd.DataFrame(liste_fichier)\n",
    "  colonnes_suppr = df_doc_budgetaire.columns.intersection(['NatCEPL', 'Departement'])\n",
    "  df_doc_budgetaire = df_doc_budgetaire.drop(columns=colonnes_suppr)\n",
    "  df_doc_budgetaire = df_doc_budgetaire.rename(columns={'IdColl' : 'Siret' })\n",
    "  df_doc_budgetaire['Siren'] = df_doc_budgetaire['Siret'].str.slice(0,9)\n",
    "  return df_doc_budgetaire\n",
    "\n",
    "def verification_presence_id_table(id_fichier : str, conn, class_bloc_budget) : \n",
    " '''Renvoie le nombre de fois où Id_Fichier est dans la base'''\n",
    " count = Select(func.count(\"*\")).select_from(class_bloc_budget).where(class_bloc_budget.Id_Fichier == id_fichier)\n",
    " requete = conn.execute(count).fetchone()\n",
    " return requete \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_bdd(chemin_des_xml) :\n",
    " ''' Fonction principale : \n",
    " Extrait les données des xml dans le dossier et les envoie dans la table'''\n",
    " chemin_xml_entree_glob = glob.glob(os.path.join(chemin_des_xml, \"*.gz\"))\n",
    "\n",
    " engine = sqlalchemy.create_engine('postgresql://verzochia:verzochia@localhost:5432/db_v1')\n",
    " conn = engine.connect()\n",
    " metadata = MetaData()\n",
    " \n",
    " class Base(DeclarativeBase):\n",
    "    pass\n",
    " \n",
    " class document_budgetaire(Base) :\n",
    "    __table__ = Table('document_budgetaire', Base.metadata, autoload_with = engine)\n",
    "\n",
    " for fichier in chemin_xml_entree_glob : \n",
    "  id_fichier = extraction_id(fichier)\n",
    "\n",
    "  if id_fichier is None : \n",
    "   print('vide')\n",
    "   pass \n",
    "  else :\n",
    "   comptage_presence = verification_presence_id_table(id_fichier, \n",
    "                                                      conn, \n",
    "                                                      document_budgetaire) \n",
    "   if comptage_presence[0] > 0 : \n",
    "      print(f'Fichier {id_fichier} déjà extrait dans la base ! ')\n",
    "      pass \n",
    "   elif comptage_presence[0] == 0 :\n",
    "    try : \n",
    "     #Preparation extration  \n",
    "     fichier_parse = parse_fichier(fichier)\n",
    "     chemin_exer = fichier_parse['DocumentBudgetaire']['Budget']['BlocBudget']['Exer']\n",
    "     chemin_nomenclature = fichier_parse['DocumentBudgetaire']['Budget']['EnTeteBudget']['Nomenclature']\n",
    "     dict_metadonnees = {'Id_Fichier' : id_fichier, \n",
    "                         'Nomenclature' : chemin_nomenclature.get('@V'),\n",
    "                         'Exer' : chemin_exer.get('@V')}\n",
    "     dict_id = {'Id_Fichier' : id_fichier}\n",
    "\n",
    "     #extraction et insertion doc budget (table centrale)\n",
    "     df_doc_budget = extraction_document_budgetaire(fichier_parse, dictionnaire_id= dict_id)\n",
    "     df_doc_budget.to_sql('document_budgetaire', engine ,if_exists = 'append', index = False, method = 'multi')\n",
    "     \n",
    "     #df_budget\n",
    "     df_budget = extraction_budget(fichier_parse, dict_metadonnees)\n",
    "     df_budget.to_sql('bloc_budget', engine ,if_exists = 'append', index = False, method = 'multi')\n",
    "\n",
    "     #Annexes \n",
    "     chemin_general_annexe = fichier_parse['DocumentBudgetaire']['Budget']['Annexes']\n",
    "     for data_annexe in LIST_ANNEXES : \n",
    "      annexe_maj = data_annexe.split('DATA_')[1]\n",
    "      data_annexe_min = annexe_maj.lower()\n",
    "      try :\n",
    "       bloc_annexe = chemin_general_annexe[data_annexe][annexe_maj]\n",
    "       df_annexe = pd.DataFrame(extraction_annexe(bloc_annexe, dict_metadonnees))\n",
    "       df_annexe.to_sql(data_annexe_min, engine, if_exists = 'append', index = False, method = 'multi')\n",
    "      except Exception as e : \n",
    "        None \n",
    "\n",
    "      \n",
    "    except Exception as e : \n",
    "      print(id_fichier, 'erreur')\n",
    "      print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_document(chemin_des_xml) :\n",
    " ''' Permet d'extraire localement les doc budgetaire'''\n",
    " chemin_xml_entree_glob = glob.glob(os.path.join(chemin_des_xml, \"*.gz\"))\n",
    " #connection à la table\n",
    " liste_df = []\n",
    "\n",
    " for fichier in chemin_xml_entree_glob : \n",
    "  id_fichier = extraction_id(fichier)\n",
    "  #print(id_fichier)\n",
    "  #Necessite verif dans tables\n",
    "  if id_fichier is None : \n",
    "   print('vide')\n",
    "   pass \n",
    "  else : \n",
    "   try : \n",
    "    #print('etape 2')\n",
    "    fichier_parse = parse_fichier(fichier)\n",
    "    dict_id = {'Id_Fichier' : id_fichier}\n",
    "    #print(dict_metadonnees)\n",
    "    df_doc = extraction_document_budgetaire(fichier_parse, dict_id)\n",
    "    liste_df.append(df_doc)\n",
    "    #insertion dans table\n",
    "   except Exception as e : \n",
    "     print(id_fichier, 'erreur')\n",
    "     print(e)\n",
    " \n",
    " df_mega = pd.concat(liste_df)\n",
    " return df_mega "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
