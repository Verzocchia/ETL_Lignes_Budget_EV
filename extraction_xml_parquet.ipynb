{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les détails, ça se passe dans le dossier \"aventures\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif ici est d'expliquer dans les grandes lignes comment fonctionnent les différentes task qui seront intégrées dans le dag,mettre au propre (pep8) les fonctions, les regrouper dans un seul endroit etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrée : Fichiers xml\n",
    "\n",
    "Sortie : Un seul fichier parquet avec en plus un fichier parquet pour chaque fichier xml afin de transmettre les informations entre les task. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Texte alternatif](./rpz_task.drawio.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 \n",
    "\n",
    "Airflow ne peut pas conserver en mémoire de grandes quantités de données via xcom, la task 1 est là pour répondre à ce problème : \n",
    "\n",
    "Elle va, sur chaque fichier xml présent dans todo_xml : \n",
    "\n",
    "- Extraire les lignes budgets\n",
    "- Y ajouter les métadonnées et l'id fichier\n",
    "- Traiter les MtSup et CaracSup\n",
    "- En faire un DataFrame avec Pandas (car peu de données)\n",
    "- Nettoyer les @V \n",
    "- Transformer le résultat en fichier parquet dans todo_parquet\n",
    "\n",
    "Notes & WIP : \n",
    "- Prend environ 20min (entre 18 et 21)\n",
    "- Il n'y a pas encore de vérification d'ID dans la bdd / dans le parquet final\n",
    "- Le schéma devrait être intégré dans cette partie \n",
    "- Il reste encore une petite modif à faire à transformation mtsup pour lorsque ça n'existe pas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 \n",
    "\n",
    "La task 2 va assembler tout les fichiers parquet dans todo_parquet et les assembler dans un seul parquet avec un schéma\n",
    "\n",
    "Notes & WIP : \n",
    "- Prend entre 2 et 3min pour les 20000 parquets\n",
    "- Le schéma est encore loin d'être parfait \n",
    "- Le parquet est pour le moment \"stable\", c'est une solution temporaire avant d'avoir une db et un flux continu \n",
    "- Dans les faits, il me sert surtout à voir que les fichier sont bien traités "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import polars as pl \n",
    "import gzip \n",
    "from lxml import etree\n",
    "import pandas as pd \n",
    "import xmltodict\n",
    "import glob\n",
    "import os \n",
    "import time \n",
    "import polars as pl \n",
    "import duckdb\n",
    "import shutil \n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions dans les tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timtim(fonction):\n",
    " ''' Permet de compter le temps de travail necessaire sur un fichier'''\n",
    " def wrapper(*args, **kwargs):\n",
    "  debut = time.time()\n",
    "  resultat = fonction(*args, **kwargs)\n",
    "  fin = time.time()\n",
    "  temps_execution = fin - debut\n",
    "  print(f\"La fonction {fonction.__name__} a pris {temps_execution:.5f} secondes pour s'exécuter.\")\n",
    "  return resultat\n",
    " return wrapper\n",
    "\n",
    "def parse_fichier(chemin) : \n",
    " '''Ouvre et parse le fichier gzip'''\n",
    " with gzip.open(chemin, 'rb') as fichier_ouvert : \n",
    "  fichier_xml_gzip = fichier_ouvert.read()\n",
    "  fichier_xml = fichier_xml_gzip.decode('latin-1')\n",
    "  fichier_dict = xmltodict.parse(fichier_xml)\n",
    " return fichier_dict\n",
    "\n",
    "def recherche_id_fichier(chemin_parquet) :\n",
    " ''' Pas encore utilisée, permet de récupérer les ID dans le parquet contenant les \n",
    " données déjà traitées '''\n",
    " conduck = duckdb.connect(database=':memory:', read_only=False)\n",
    " docubudg_t = conduck.read_parquet(chemin_parquet)\n",
    " requete_duckdb = ''' \n",
    " SELECT\n",
    "    DISTINCT Id_Fichier\n",
    " FROM \n",
    "    docubudg_t\n",
    " '''\n",
    " result_requete= conduck.execute(requete_duckdb).fetchdf()\n",
    " liste_id = result_requete['Id_Fichier'].to_list()\n",
    " conduck.close()\n",
    " return liste_id\n",
    "\n",
    "def _isolement_id(fichier) : \n",
    " '''Extrait l'id du nom du fichier pour la liste comprehension de securité\n",
    "\n",
    " ATTENTION, le premier split / va changer si on l'applique sur du minio '''\n",
    " val_id_fichier_source = fichier.split(\"\\\\\")[-1].split('.')[0]\n",
    " if '-' in val_id_fichier_source : \n",
    "  val_id_fichier = val_id_fichier_source.split('-')[1]\n",
    " else : \n",
    "  val_id_fichier= val_id_fichier_source\n",
    " return val_id_fichier\n",
    "\n",
    "def nettoyage_V(dataframe : pd.DataFrame) -> pd.DataFrame :\n",
    " ''' Permet de supprimer les @V des colonnes à l'exception de MtSup et CaracSup'''\n",
    "\n",
    " nettoyage = lambda x : str(x).replace(\"{'@V': '\", \"\").replace(\"'}\", \"\")\n",
    " for col in dataframe.columns : \n",
    "  if col in ['CaracSup', 'CaracSup'] : \n",
    "   dataframe[col] = dataframe[col].astype(str) \n",
    "  else :\n",
    "   dataframe[col] = dataframe[col].apply(nettoyage)\n",
    " dataframe_propre = dataframe.reset_index(drop=True)\n",
    " return dataframe_propre\n",
    "\n",
    "def transformation_mtsup(lignes_budget: dict) -> dict:\n",
    " ''' Traite les MtSup, qu'ils soient sous forme de list ou de dict '''\n",
    "\n",
    " for i in lignes_budget:\n",
    "  type_mtsup = i.get('MtSup')  # Permet de connaitre le type de MtSup\n",
    "  if type_mtsup is not None:  # Vérifie si la clé 'MtSup' existe\n",
    "    if isinstance(type_mtsup, dict):\n",
    "      dict_mtsup = type_mtsup\n",
    "      i['MtSup_1_Lib'] = {'@V': dict_mtsup.get('@Code', '')}\n",
    "      i['MtSup_1_Val'] = {'@V': dict_mtsup.get('@V', '')}\n",
    "    elif isinstance(type_mtsup, list):\n",
    "      dict_mtsup = i['MtSup']\n",
    "      mtsup_propre = {}\n",
    "      for z, entry in enumerate(dict_mtsup, start=1):\n",
    "        code = f'MtSup_{z}_Lib'\n",
    "        valeur = f'MtSup_{z}_Val'\n",
    "        mtsup_propre[code] = entry.get('@Code', '')\n",
    "        mtsup_propre[valeur] = entry.get('@V', '')\n",
    "        i.update(mtsup_propre)\n",
    " return lignes_budget\n",
    "\n",
    "def transformation_caracsup(lignes_budget: dict) -> dict:\n",
    " ''' Pareil que transfo_MtSup mais pour CaracSup'''\n",
    "\n",
    " for i in lignes_budget:\n",
    "  type_caracsup = i.get('CaracSup')  # Permet de connaitre le type de CaracSup\n",
    "  if type_caracsup is not None:  # Vérifie si la clé 'CaracSup' existe\n",
    "    if isinstance(type_caracsup, dict):\n",
    "      dict_caracsup = type_caracsup\n",
    "      i['CaracSup_1_Lib'] = {'@V': dict_caracsup.get('@Code', '')}\n",
    "      i['CaracSup_1_Val'] = {'@V': dict_caracsup.get('@V', '')}\n",
    "    elif isinstance(type_caracsup, list):\n",
    "      dict_caracsup = i['CaracSup']\n",
    "      caracsup_propre = {}\n",
    "      for z, entry in enumerate(dict_caracsup, start=1):\n",
    "        code = f'CaracSup_{z}_Lib'\n",
    "        valeur = f'CaracSup_{z}_Val'\n",
    "        caracsup_propre[code] = entry.get('@Code', '')\n",
    "        caracsup_propre[valeur] = entry.get('@V', '')\n",
    "        i.update(caracsup_propre)      \n",
    " return lignes_budget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_1(chemin) : \n",
    " ''' Traite les XML et les envoies sous format parquet,\n",
    "   le nettoyage des @V est fait à cette étape'''\n",
    " \n",
    " for fichier in glob.glob(os.path.join(chemin, \"*.gz\")) : \n",
    "  try : \n",
    "   id_fichier = _isolement_id(fichier)\n",
    "   dico = parse_fichier(fichier)\n",
    "   metadonnees = dico['DocumentBudgetaire']['EnTeteDocBudgetaire']\n",
    "   metadonnees['Id_Fichier'] = {'@V' : id_fichier}\n",
    "   docbase = dico['DocumentBudgetaire']['Budget']['LigneBudget']\n",
    "   if isinstance(docbase, list):\n",
    "    for i in docbase : \n",
    "      i.update(metadonnees)\n",
    "   elif isinstance(docbase, dict) : \n",
    "    docbase.update(metadonnees)\n",
    "   docbase = transformation_caracsup(docbase)\n",
    "   docbase = transformation_mtsup(docbase)\n",
    "   df_base = pd.DataFrame(docbase)\n",
    "   df_propre = nettoyage_V(df_base)\n",
    "   df_propre.to_parquet(f'./fichiers/todo_parquet/{id_fichier}_pyarrow', engine='pyarrow')\n",
    "   #shutil.move(fichier, './fichiers/done_xml/')\n",
    "  except Exception as e : \n",
    "    print(f'Erreur fichier {fichier}, extraction impossible')\n",
    "    #shutil.move(fichier, './fichiers/todo_xml/error/')\n",
    "    print(e)\n",
    "    continue  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema \n",
    "\n",
    "custom_schema = pa.schema([\n",
    "        ('Nature', pa.string()),\n",
    "        ('Fonction', pa.string()),\n",
    "        ('LibCpte', pa.string()),\n",
    "        ('ContNat', pa.string()),\n",
    "        ('ArtSpe', pa.string()), #Doit être corrigé en bool,\n",
    "        ('ContFon', pa.string()),\n",
    "        ('CodRD', pa.string()), #Val D ou R,\n",
    "        ('MtBudgPrec', pa.string()), #float32 #nullable = True\n",
    "        ('MtRARPrec', pa.string()), #float32\n",
    "        ('MtPropNouv', pa.string()), #float32\n",
    "        ('MtPrev', pa.string()), #float32\n",
    "        ('CredOuv', pa.string()), #int32\n",
    "        ('MtReal', pa.string()), #float32\n",
    "        ('MtRAR3112', pa.string()), #float32\n",
    "        ('OpBudg', pa.string()),\n",
    "        ('MtSup', pa.string()),\n",
    "        ('MtSup_1_Lib', pa.string()),\n",
    "        ('MtSup_1_Val', pa.string()),\n",
    "        ('MtSup_2_Lib', pa.string()),\n",
    "        ('MtSup_2_Val', pa.string()),\n",
    "        ('MtSup_3_Lib', pa.string()),\n",
    "        ('MtSup_3_Val', pa.string()),\n",
    "        ('MtSup_4_Lib', pa.string()),\n",
    "        ('MtSup_4_Val', pa.string()),\n",
    "        ('MtSup_5_Lib', pa.string()),\n",
    "        ('MtSup_5_Val', pa.string()),\n",
    "        ('MtSup_6_Lib', pa.string()),\n",
    "        ('MtSup_6_Val', pa.string()),\n",
    "        ('MtSup_7_Lib', pa.string()),\n",
    "        ('MtSup_7_Val', pa.string()),\n",
    "        ('MtSup_8_Lib', pa.string()),\n",
    "        ('MtSup_8_Val', pa.string()),\n",
    "        ('MtSup_9_Lib', pa.string()),\n",
    "        ('MtSup_9_Val', pa.string()),\n",
    "        ('MtSup_10_Lib', pa.string()),\n",
    "        ('MtSup_10_Val', pa.string()), #10\n",
    "        ('CaracSup_1_Lib', pa.string()),\n",
    "        ('CaracSup_1_Val', pa.string()),\n",
    "        ('CaracSup_2_Lib', pa.string()),\n",
    "        ('CaracSup_2_Val', pa.string()),\n",
    "        ('CaracSup_3_Lib', pa.string()),\n",
    "        ('CaracSup_3_Val', pa.string()),\n",
    "        ('CaracSup_4_Lib', pa.string()),\n",
    "        ('CaracSup_4_Val', pa.string()),\n",
    "        ('CaracSup_5_Lib', pa.string()),\n",
    "        ('CaracSup_5_Val', pa.string()),\n",
    "        ('CaracSup_6_Lib', pa.string()),\n",
    "        ('CaracSup_6_Val', pa.string()),\n",
    "        ('CaracSup_7_Lib', pa.string()), #7\n",
    "        ('CaracSup_7_Val', pa.string()),\n",
    "        ('TypOpBudg', pa.string()), #des 2 et des 1\n",
    "        ('OpeCpteTiers', pa.string()),\n",
    "        ('DteStr', pa.date32()),\n",
    "        ('LibellePoste', pa.string()),\n",
    "        ('IdPost', pa.string()),\n",
    "        ('LibelleColl', pa.string()),\n",
    "        ('IdColl', pa.string()),\n",
    "        ('NatCEPL', pa.string()),\n",
    "        ('Departement', pa.string()), #On oublie pas les 2A,\n",
    "        ('Id_Fichier', pa.int64())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2(dossier, nom_parquet, schema_cust) :\n",
    " liste_parquet_t = []\n",
    " for parquet in glob.glob(os.path.join(dossier, \"*\")) : \n",
    "  liste_parquet_t.append(parquet)\n",
    "\n",
    " schema = schema_cust\n",
    " #schema = pq.ParquetFile(liste_parquet_t[0]).schema_arrow\n",
    " with pq.ParquetWriter(f\"{nom_parquet}.parquet\", schema=schema) as writer:\n",
    "    for file in liste_parquet_t:\n",
    "        table = pq.read_table(file, schema=schema)\n",
    "        writer.write_table(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
