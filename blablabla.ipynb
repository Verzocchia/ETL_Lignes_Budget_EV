{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import glob\n",
    "import json\n",
    "import logging \n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import MetaData, select, func, Table\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "\n",
    "#log\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "LISTE_COL_DOCUMENT_BUDGETAIRE = [['Id_Fichier','Nomenclature','Exer','Siret',\n",
    " 'Siren','CodColl','DteStr','Date','DteDec','DteDecEx','NumDec','IdPost',\n",
    " 'LibellePoste','LibelleColl','IdEtabPal','LibelleEtabPal','LibelleEtab','IdEtab',\n",
    " 'NatDec','NatVote','OpeEquip','CodInseeColl','VoteFormelChap','TypProv','BudgPrec',\n",
    " 'RefProv','ReprRes','NatFonc','PresentationSimplifiee','DepFoncN2','RecFoncN2',\n",
    " 'DepInvN2','RecInvN2','CodTypBud','CodBud','ProjetBudget','Affect','SpecifBudget','FinJur',\n",
    " 'Md5',\n",
    " 'Sha1']]\n",
    "\n",
    "LISTE_COL_SUPPRESSION_BUDGET = [\n",
    "  'Code_nat_compte', 'code_nat_chap', 'Code_nat_chap',\n",
    "  'Code_fonc_compte','code_fonc_chap','Code_fonc_chap', 'Code_mixte',\n",
    "  'code_chap_mixte']\n",
    "\n",
    "LISTE_COL_MINIMALE_BUDGET = [\n",
    " 'Id_Fichier','Nomenclature', 'Exer', 'TypOpBudg','Operation', 'Nature', 'ContNat',\n",
    " 'LibCpte', 'Fonction', 'ContFon', 'ArtSpe', 'CodRD', 'MtBudgPrec', 'MtRARPrec',\n",
    " 'MtPropNouv', 'MtPrev', 'OpBudg', 'CredOuv','MtReal', 'MtRAR3112', 'ContOp', 'OpeCpteTiers',\n",
    " 'MtSup', 'MtSup_APVote', 'MtSup_Brut', 'MtSup_BudgetHorsRAR', 'MtSup_Comp', 'MtSup_ICNE', 'MtSup_ICNEPrec',\n",
    " 'MtSup_MtOpeCumul', 'MtSup_MtOpeInfo', 'MtSup_Net', 'MtSup_MtPropNouv', 'MtSup_ProdChaRat', 'MtSup_RARPrec',\n",
    " 'CaracSup', 'CaracSup_TypOpe', 'CaracSup_Section', 'CaracSup_ChapSpe',\n",
    "  'CaracSup_ProgAutoLib', 'CaracSup_ProgAutoNum','CaracSup_VirCredNum', 'CaracSup_CodeRegion']\n",
    "\n",
    "LIST_ANNEXES = ['DATA_AMORTISSEMENT_METHODE', 'DATA_APCP', 'DATA_AUTRE_ENGAGEMENT',\n",
    "        'DATA_CHARGE', 'DATA_CONCOURS', 'DATA_CONSOLIDATION', 'DATA_CONTRAT_COUV', \n",
    "        \"DATA_CONTRAT_COUV_REFERENCE\", \"DATA_CREDIT_BAIL\", \"DATA_DETTE\", \"DATA_EMPRUNT\", \n",
    "        \"DATA_ETAB_SERVICE\", \"DATA_FISCALITE\", \"DATA_FOND_AIDES_ECO\", \"DATA_FOND_COMM_HEBERGEMENT\", \n",
    "        \"DATA_FOND_EUROPEEN\", \"DATA_FOND_EUROPEEN_PROGRAMMATION\", \"DATA_FORMATION\", \n",
    "        \"DATA_FORMATION_PRO_JEUNES\", \"DATA_MEMBRESASA\", \"DATA_ORGANISME_ENG\", \n",
    "        \"DATA_ORGANISME_GROUP\", \"DATA_PATRIMOINE\", \"DATA_PERSONNEL\", \"DATA_PERSONNEL_SOLDE\", \n",
    "        \"DATA_PPP\", \"DATA_PRET\", \"DATA_PROVISION\", \"DATA_RECETTE_AFFECTEE\", \n",
    "        \"DATA_SERVICE_FERROVIAIRE_BUD\", \"DATA_SERVICE_FERROVIAIRE_PATRIM\", \n",
    "        \"DATA_SERVICE_FERROVIAIRE_TER\", \"DATA_SIGNATAIRE\", \"DATA_SIGNATURE\", \n",
    "        \"DATA_SOMMAIRE\", \"DATA_TIERS\", \"DATA_TRESORERIE\", \"DATA_VENTILATION\", \"DATA_FLUX_CROISES\"]\n",
    "\n",
    "LISTE_COL_MAJ_BUDGET = [\n",
    "    'MtSup_APVote', 'MtSup_Brut', 'MtSup_BudgetHorsRAR', 'MtSup_Comp', \n",
    "    'MtSup_ICNE', 'MtSup_ICNEPrec', 'MtSup_MtOpeCumul','MtSup_MtOpeInfo', \n",
    "    'MtSup_Net', 'MtSup_ProdChaRat', 'MtSup_RARPrec',\n",
    "    'CaracSup_TypOpe', 'CaracSup_Section', 'CaracSup_ChapSpe',\n",
    "    'CaracSup_ProgAutoLib', 'CaracSup_ProgAutoNum',\n",
    "    'CaracSup_VirCredNum', 'CaracSup_CodeRegion']\n",
    "\n",
    "\n",
    "def ouverture_connection_postgres(connection_id):\n",
    "    conn = Connection.get_connection_from_secrets(connection_id)\n",
    "    return sqlalchemy.create_engine(f'postgresql://{conn.login}:{conn.password}@{conn.host}:{conn.port}/{conn.schema}')\n",
    "\n",
    "def extraction_id(fichier : str) -> str : \n",
    "  '''Extrait l'id du fichier, renvoie un str. '''\n",
    "\n",
    "  val_id_fichier = fichier.split(\"/\")[-1].split('.')[0]\n",
    "\n",
    "  return val_id_fichier\n",
    "\n",
    "def parse_fichier(chemin : str) -> dict: \n",
    "  '''Ouvre et parse le fichier gzip en dictionnaire'''\n",
    "\n",
    "  with gzip.open(chemin, 'rb') as fichier_ouvert :\n",
    "\n",
    "   fichier_xml_gzip = fichier_ouvert.read()\n",
    "   fichier_xml = fichier_xml_gzip.decode('latin-1')\n",
    "   fichier_dict = xmltodict.parse(fichier_xml)\n",
    "  return fichier_dict\n",
    "\n",
    "def extraction_annexe(chemin_annexe : dict, dict_metadonnees : dict) -> list :\n",
    "  ''' Extrait les annexes pour les préparer à passer dans un dataframe''' \n",
    "  liste_annexe = []\n",
    "  for row in chemin_annexe : \n",
    "   liste_par_ligne = {}\n",
    "   for a, b in row.items() : \n",
    "    liste_par_ligne.update({a : b.get('@V')})\n",
    "    liste_par_ligne.update(dict_metadonnees)\n",
    "   liste_annexe.append(liste_par_ligne)\n",
    "  return liste_annexe \n",
    "\n",
    "def extraction_donnees(chemin : dict) -> dict  : \n",
    "  ''' Permet de passer de {'@V' : 'XDZ', '@Code' : 'blab'} à {'blab' : 'XDZ'}'''\n",
    "  dict_annexe = {}\n",
    "  for a, b in chemin.items() : \n",
    "    dict_annexe.update({a : b.get('@V')})\n",
    "  return dict_annexe \n",
    "\n",
    "def extraction_lignes_budget_liste(chemin : dict, dict_id : dict) -> list :\n",
    "  ''' Explicite '''\n",
    "  liste_budget = []\n",
    "  for lignes in chemin : \n",
    "   dict_ligne = {}\n",
    "   dict_ligne.update(dict_id)\n",
    "   for a, b in lignes.items() :\n",
    "      if a not in ['MtSup', 'CaracSup'] : \n",
    "        dict_ligne.update({a : b.get('@V')}) \n",
    " \n",
    "      elif a == 'MtSup' : \n",
    "        dict_ligne.update({a : json.dumps(b)})\n",
    "        type_m = lignes.get('MtSup')\n",
    "  \n",
    "        if isinstance(type_m, dict) : \n",
    "         dict_ligne.update({f\"MtSup_{type_m.get('@Code')}\" : type_m.get('@V')})\n",
    "  \n",
    "        elif isinstance(type_m, list) :\n",
    "           for j in b : \n",
    "            dict_ligne.update({f\"MtSup_{j.get('@Code')}\" : j.get('@V')})\n",
    "  \n",
    "      elif a == 'CaracSup' :   \n",
    "        type_c = lignes.get('CaracSup')\n",
    "        dict_ligne.update({a : json.dumps(b)}) \n",
    " \n",
    "        if isinstance(type_c, dict) :\n",
    "         dict_ligne.update({f\"CaracSup_{type_c.get('@Code')}\" : type_c.get('@V')})\n",
    "  \n",
    "        elif isinstance(type_c, list) : \n",
    "           for j in b : \n",
    "            dict_ligne.update({f\"CaracSup_{j.get('@Code')}\" : j.get('@V')})\n",
    " \n",
    "   liste_budget.append(dict_ligne)\n",
    "  return liste_budget\n",
    "\n",
    "def mise_au_norme_document_budgetaire(df, class_doc_budg) :\n",
    "  ''' Verifie que le df n'ait que des colonnes qui sont dans la table document_budgetaire'''\n",
    "  liste_to_suppr = []\n",
    "  liste_col_table = list(class_doc_budg.__table__.columns.keys())\n",
    "\n",
    "  for col in df.columns : \n",
    "    if col not in liste_col_table : \n",
    "      liste_to_suppr.append(col)\n",
    "\n",
    "  df_au_norme = df.drop(columns=liste_to_suppr)\n",
    "  if liste_to_suppr: \n",
    "      logger.info(f\"Fichier {df['Id_Fichier'].iloc[0]}, 'col pas dans le schema :', {liste_to_suppr}\")\n",
    "\n",
    "  return df_au_norme\n",
    "\n",
    "def extraction_budget(fichier_parse : dict , infos_doc_budgetaire : dict)  -> pd.DataFrame : \n",
    "  ''' Extrait toutes les données budgetaires, y compris carac et mtsup '''\n",
    "  lignes_budget = fichier_parse['DocumentBudgetaire']['Budget']['LigneBudget'] \n",
    " \n",
    "  if isinstance(lignes_budget, dict) : \n",
    "   donnees_budget_prep = extraction_donnees(lignes_budget)\n",
    "   donnees_budget_prep.update(infos_doc_budgetaire)\n",
    "   donnees_budget = [donnees_budget_prep]\n",
    "\n",
    "  elif isinstance(lignes_budget, list) : \n",
    "   donnees_budget = extraction_lignes_budget_liste(lignes_budget, infos_doc_budgetaire)\n",
    " \n",
    "  df_budget = pd.DataFrame(donnees_budget)\n",
    "  return df_budget \n",
    "\n",
    "def extraction_document_budgetaire(fichier_parse : dict, dictionnaire_id : dict) -> pd.DataFrame : \n",
    "  ''' Extrait les métadonnées du fichier pour la table document_budgetaire '''\n",
    "  blocbudget = extraction_donnees(fichier_parse['DocumentBudgetaire']['Budget']['BlocBudget'])\n",
    "  entetedocbudg = extraction_donnees(fichier_parse['DocumentBudgetaire']['EnTeteDocBudgetaire'])\n",
    "  entetebudget = extraction_donnees(fichier_parse['DocumentBudgetaire']['Budget']['EnTeteBudget'])\n",
    "  scellement = {'Date' : fichier_parse['DocumentBudgetaire']['Scellement'].get('@date'),\n",
    "                'Md5' : fichier_parse['DocumentBudgetaire']['Scellement'].get('@md5'), \n",
    "                'Sha1' : fichier_parse['DocumentBudgetaire']['Scellement'].get('@sha1')}\n",
    "\n",
    "  liste_fichier = [{**blocbudget, **entetedocbudg, **entetebudget, **scellement, **dictionnaire_id}]\n",
    "  df_doc_budgetaire = pd.DataFrame(liste_fichier)\n",
    "  colonnes_suppr = df_doc_budgetaire.columns.intersection(['NatCEPL', 'Departement'])\n",
    "  df_doc_budgetaire = df_doc_budgetaire.drop(columns=colonnes_suppr)\n",
    "  df_doc_budgetaire = df_doc_budgetaire.rename(columns={'IdColl' : 'Siret' })\n",
    "  df_doc_budgetaire['Siren'] = df_doc_budgetaire['Siret'].str.slice(0,9)\n",
    "  return df_doc_budgetaire\n",
    "\n",
    "def verification_presence_id_table(id_fichier : str, conn, class_bloc_budget) : \n",
    "  '''Renvoie le nombre de fois où Id_Fichier est dans la base'''\n",
    "  count = select(func.count(\"*\")).select_from(class_bloc_budget).where(class_bloc_budget.Id_Fichier == id_fichier)\n",
    "  requete = conn.execute(count).fetchone()\n",
    "  return requete \n",
    "\n",
    "def transcodage_bloc(dataframe_bloc, dictionnaire_transcodage) : \n",
    "  'Exploite le dictionnaire de données déjà sous format dict'\n",
    "  for col in dataframe_bloc.columns : \n",
    "    if col in dictionnaire_transcodage.keys() : \n",
    "      dataframe_bloc[col] = dataframe_bloc[col].replace(dictionnaire_transcodage.get(col))\n",
    "  return dataframe_bloc\n",
    "\n",
    "def nettoyage_colonnes(df_budget, liste_colonnes_propre) :\n",
    "  ''' Remplace les MtSupRARprec etc. par MtSupRARPrec pour que ça rentre en bdd\n",
    "  C'est pas une belle fonction, ça c'est sûr, mais c'est une rustine qui fonctionne'''\n",
    "  dict_replace = {}\n",
    "  for col_budget in df_budget.columns:\n",
    "      col_budget_min = col_budget.lower()\n",
    "\n",
    "      for col_propre in liste_colonnes_propre:\n",
    "        col_propre_min = col_propre.lower()\n",
    "\n",
    "        if col_budget_min == col_propre_min:\n",
    "            dict_replace.update({col_budget : col_propre})\n",
    "\n",
    "  df_budget = df_budget.rename(columns=dict_replace)\n",
    "  return df_budget\n",
    "\n",
    "def _jointure_libelle_nature_chap(df : pd.DataFrame,\n",
    "                                df_nature_chap : pd.DataFrame) -> pd.DataFrame :\n",
    "  ''' Necessite l'existence d'une colonne opération, qui est normalement optionnelle'''\n",
    "  if 'Operation' in df.columns : \n",
    "    for index, row in df.iterrows():\n",
    "      if row['CodRD'] == 'D' and row['OpBudg'] == '1' and row['TypOpBudg'] == '2':\n",
    "        df.at[index, 'code_nat_chap'] = row['DOES_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'DOES'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '1' and row['TypOpBudg'] == '2':\n",
    "        df.at[index, 'code_nat_chap'] = row['ROES_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'ROES'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '1' and row['TypOpBudg'] == '1':\n",
    "        df.at[index, 'code_nat_chap'] = row[ 'DOIS_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'DOIS'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '1' and row['TypOpBudg'] == '1':\n",
    "        df.at[index, 'code_nat_chap'] = row[ 'ROIS_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'ROIS'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) and pd.isna(row['Operation']):\n",
    "        df.at[index, 'code_nat_chap'] = row['RR_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'RR'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) and pd.isna(row['Operation']):\n",
    "        df.at[index, 'code_nat_chap'] = row['DR_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'DR'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) and pd.notna(row['Operation']):\n",
    "        df.at[index, 'code_nat_chap'] = row['DEquip_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'DEquip'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) and pd.notna(row['Operation']):\n",
    "        df.at[index, 'code_nat_chap'] = row['REquip_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'REquip'\n",
    "  else :\n",
    "    for index, row in df.iterrows():\n",
    "      if row['CodRD'] == 'D' and row['OpBudg'] == '1' and row['TypOpBudg'] == '2':\n",
    "        df.at[index, 'code_nat_chap'] = row['DOES_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'DOES'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '1' and row['TypOpBudg'] == '2':\n",
    "        df.at[index, 'code_nat_chap'] = row['ROES_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'ROES'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '1' and row['TypOpBudg'] == '1':\n",
    "        df.at[index, 'code_nat_chap'] = row['DOIS_nat_compte']\n",
    "        df.at[index, 'val_prise'] = 'DOIS'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '1' and row['TypOpBudg'] == '1':\n",
    "        df.at[index, 'code_nat_chap'] = row['ROIS_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'ROIS'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) :\n",
    "        df.at[index, 'code_nat_chap'] = row['RR_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'RR'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) :\n",
    "        df.at[index, 'code_nat_chap'] = row['DR_nat_compte']\n",
    "        df.at[index, 'type_nature'] = 'DR' \n",
    "\n",
    "  df['code_nat_chap'] = df['code_nat_chap'].astype(str)\n",
    "  df = df.merge(df_nature_chap, \n",
    "                left_on = ['Exer','Nomenclature','code_nat_chap'],\n",
    "                right_on = ['Exer','Nomenclature','Code_nat_chap'],\n",
    "                how = 'left')\n",
    "  return df\n",
    "\n",
    "def _jointure_libelle_fonction_chap(df : pd.DataFrame, \n",
    "                        df_fonction_chap : pd.DataFrame) -> pd.DataFrame : \n",
    "  ''' Necessite l'existence d'une colonne opération, qui est normalement optionnelle'''\n",
    "  if 'Operation' in df.columns : \n",
    "    for index, row in df.iterrows():\n",
    "      if row['CodRD'] == 'D' and row['OpBudg'] == '1' and row['TypOpBudg'] == '2':\n",
    "        df.at[index, 'code_fonc_chap'] = row['DOES_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'DOES'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '1' and row['TypOpBudg'] == '2':\n",
    "        df.at[index, 'code_fonc_chap'] = row['ROES_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'ROES'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '1' and row['TypOpBudg'] == '1':\n",
    "        df.at[index, 'code_fonc_chap'] = row[ 'DOIS_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'DOIS'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '1' and row['TypOpBudg'] == '1':\n",
    "        df.at[index, 'code_fonc_chap'] = row[ 'R_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'ROIS'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) and pd.isna(row['Operation']):\n",
    "        df.at[index, 'code_fonc_chap'] = row['RR_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'RR'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) and pd.isna(row['Operation']):\n",
    "        df.at[index, 'code_fonc_chap'] = row['DR_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'DR'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) and pd.notna(row['Operation']):\n",
    "        df.at[index, 'code_fonc_chap'] = row['DEquip_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'DEquip'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) and pd.notna(row['Operation']):\n",
    "        df.at[index, 'code_fonc_chap'] = row['REquip_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'REquip'\n",
    "  else :\n",
    "    for index, row in df.iterrows():\n",
    "      if row['CodRD'] == 'D' and row['OpBudg'] == '1' and row['TypOpBudg'] == '2':\n",
    "        df.at[index, 'code_fonc_chap'] = row['DOES_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'DOES'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '1' and row['TypOpBudg'] == '2':\n",
    "        df.at[index, 'code_fonc_chap'] = row['ROES_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'ROES'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '1' and row['TypOpBudg'] == '1':\n",
    "        df.at[index, 'code_fonc_chap'] = row['DOIS_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'DOIS'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '1' and row['TypOpBudg'] == '1':\n",
    "        df.at[index, 'code_fonc_chap'] = row['ROIS_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'ROIS'\n",
    "      elif row['CodRD'] == 'R' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) :\n",
    "        df.at[index, 'code_fonc_chap'] = row['RR_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'RR'\n",
    "      elif row['CodRD'] == 'D' and row['OpBudg'] == '0' and pd.isna(row['TypOpBudg']) :\n",
    "        df.at[index, 'code_fonc_chap'] = row['DR_fonc_compte']\n",
    "        df.at[index, 'type_fonction'] = 'DR' \n",
    "\n",
    "  df['code_fonc_chap'] = df['code_fonc_chap'].astype(str)\n",
    "  df = df.merge(df_fonction_chap, \n",
    "                left_on = ['Exer','Nomenclature','code_fonc_chap'],\n",
    "                right_on = ['Exer','Nomenclature','Code_fonc_chap'],\n",
    "                how = 'left')\n",
    "  return df\n",
    "\n",
    "def _jointure_fonction(df_budget : pd.DataFrame, \n",
    "                              val_NatFonc : str, \n",
    "                              df_fonction_compte : pd.DataFrame, \n",
    "                              df_fonction_chap : pd.DataFrame, \n",
    "                              df_fonction_mixte : pd.DataFrame) -> pd.DataFrame :\n",
    "  ''' Permet d'automatiser les jonctions des fonction WIP '''\n",
    "  if val_NatFonc == '1' : \n",
    "    None \n",
    "  elif val_NatFonc == '2' : \n",
    "    df_budget = df_budget.merge(df_fonction_compte,\n",
    "                  left_on = ['Nomenclature','Exer','Fonction'],\n",
    "                  right_on = ['Nomenclature','Exer','Code_fonc_compte'],\n",
    "                  how = 'left')\n",
    "    df_budget = _jointure_libelle_fonction_chap(df_budget, df_fonction_chap)\n",
    "\n",
    "  elif val_NatFonc == '3' :\n",
    "    df_budget = df_budget.merge(df_fonction_mixte,\n",
    "                  left_on = ['Nomenclature','Exer','Fonction'],\n",
    "                  right_on = ['Nomenclature','Exer','Code_mixte'],\n",
    "                  how = 'left')\n",
    "    df_budget = df_budget.merge(df_fonction_chap,\n",
    "                  left_on = ['Nomenclature','Exer','code_chap_mixte'], \n",
    "                  right_on = ['Nomenclature','Exer','Code_fonc_chap'], \n",
    "                  how = 'left')\n",
    "    df_budget.drop(columns = ['Section_fonc_chap', 'Special_fonc_chap'])\n",
    "\n",
    "  return df_budget \n",
    "\n",
    "def _jointure_nature(df_budget : pd.DataFrame,\n",
    "                  df_nature_chap : pd.DataFrame,\n",
    "                  df_nature_compte : pd.DataFrame) -> pd.DataFrame : \n",
    "\n",
    "  df_budget = df_budget.merge(df_nature_compte,\n",
    "                  left_on = ['Nomenclature','Exer','Nature'],\n",
    "                  right_on = ['Nomenclature','Exer','Code_nat_compte'],\n",
    "                  how = 'left')\n",
    "  df_budget = _jointure_libelle_nature_chap(df_budget, df_nature_chap)\n",
    "  return df_budget \n",
    "\n",
    "def jointure_libelle_comptable(df_budget : pd.DataFrame, \n",
    "                        df_nature_chap : pd.DataFrame,\n",
    "                        df_nature_compte : pd.DataFrame, \n",
    "                        df_fonction_chap : pd.DataFrame, \n",
    "                        df_fonction_compte : pd.DataFrame, \n",
    "                        df_fonction_mixte : pd.DataFrame,\n",
    "                        LISTE_COL_SUPPRESSION_BUDGET,\n",
    "                        valeur_NatFonc) -> pd.DataFrame :\n",
    "\n",
    "  df_budget = _jointure_nature(df_budget = df_budget, \n",
    "                            df_nature_chap = df_nature_chap,\n",
    "                            df_nature_compte = df_nature_compte)\n",
    "  df_budget = _jointure_fonction(df_budget, \n",
    "                            df_fonction_chap = df_fonction_chap,\n",
    "                            df_fonction_compte = df_fonction_compte,\n",
    "                            df_fonction_mixte = df_fonction_mixte, \n",
    "                            val_NatFonc = valeur_NatFonc\n",
    "                            )\n",
    "\n",
    "  for nom in LISTE_COL_SUPPRESSION_BUDGET : \n",
    "    if nom in df_budget.columns : \n",
    "      df_budget = df_budget.drop(columns = [nom])\n",
    "  return df_budget\n",
    "\n",
    "def creation_df_anomalies(df_budget: pd.DataFrame, dict_id: dict) -> pd.DataFrame:\n",
    "  ''' Permet de mettre en lumière les différentes anomalies,\n",
    "  pour le moment : fonction sans correspondances \n",
    "  \n",
    "  Necessite un envoi to_sql et la création de la table associée'''\n",
    "\n",
    "  \n",
    "  if 'Libelle_fonc_compte' in df_budget.columns :\n",
    "   sous_df = df_budget[(df_budget['Libelle_fonc_compte'].isna()) & (~df_budget['Fonction'].isna())]\n",
    "  \n",
    "   if sous_df.shape[0] == 0 : \n",
    "     None \n",
    "   elif sous_df.shape[0] > 0 : \n",
    "    df_anomalies = pd.DataFrame([dict_id])\n",
    "    fonction_sans_ref = sous_df['Fonction'].drop_duplicates().to_list()\n",
    "    nb_fonc_sans_ref = len(fonction_sans_ref)\n",
    "    data = pd.Series([fonction_sans_ref], index=['fonctions_sans_ref'])\n",
    "    df_fonc_sans_ref = pd.DataFrame(data).transpose()\n",
    "    df_anomalies = pd.concat([df_anomalies, df_fonc_sans_ref], axis = 1)\n",
    "    df_anomalies['nb_fonctions'] = nb_fonc_sans_ref\n",
    "    df_anomalies['pourcentage'] = round(sous_df.shape[0] / df_budget.shape[0] * 100, 2)\n",
    "        \n",
    "    return df_anomalies\n",
    "\n",
    "def ajout_data_siren(df_document_budgetaire, engine) : \n",
    "  ''' Jointure selective avec info siret\n",
    "  Fonctionne s'il n'y a pas de correspondance'''\n",
    "  val_siret = df_document_budgetaire.loc[0,'Siret']\n",
    "  df_siret = pd.read_sql(f''' SELECT \"siret\", \"CODGEO\", \"LIBGEO\", \"DEP\", \"REG\", \n",
    "                                     \"EPCI\", \"NATURE_EPCI\", \"libelleCategorieJuridique\", \n",
    "                                     \"denominationUniteLegale\" \n",
    "                              FROM info_siret \n",
    "                              WHERE \"siret\" = '{val_siret}' \n",
    "                              LIMIT 1''',engine )\n",
    "  df_doc_complet = df_document_budgetaire.merge(df_siret, left_on = 'Siret', \n",
    "                                                          right_on = 'siret', \n",
    "                                                          how = 'left')\n",
    "\n",
    "  return df_doc_complet\n",
    "\n",
    "\n",
    "def operate_file(file, engine):\n",
    " \n",
    "  id_fichier = extraction_id(file)\n",
    "\n",
    "  if id_fichier is None :\n",
    "    logger.info(f\"Fichier {file}, déjà dans la base\")\n",
    "    pass \n",
    "\n",
    "  else :\n",
    "\n",
    "    conn = engine.connect()\n",
    "    metadata = MetaData()\n",
    "    metadata.reflect(engine) \n",
    "\n",
    "    table_bloc_budget = metadata.tables['bloc_budget'] \n",
    "    df_bloc_budget_vide = pd.DataFrame(columns=LISTE_COL_MINIMALE_BUDGET)\n",
    "\n",
    "    Base = declarative_base()\n",
    "\n",
    "    class document_budgetaire(Base) :\n",
    "     __table__ = Table('document_budgetaire', Base.metadata, autoload_with = engine)\n",
    "       \n",
    "    #Prep transco\n",
    "    df_transco = pd.read_sql('Select * from transcodage', engine)\n",
    "    dico_transco = {j['nom_champ']: eval(j['enum']) for i, j in df_transco.iterrows()}\n",
    "\n",
    "    #prep libelle\n",
    "    df_nature_compte = pd.read_sql('SELECT * FROM nature_compte', engine)\n",
    "    df_nature_chap = pd.read_sql('SELECT * FROM nature_chapitre', engine)\n",
    "    df_fonction_compte = pd.read_sql('SELECT * FROM fonction_compte', engine)\n",
    "    df_fonction_chap = pd.read_sql('SELECT * FROM fonction_chapitre', engine)\n",
    "    df_fonction_mixte = pd.read_sql('SELECT * FROM fonction_compte_mixte', engine)\n",
    "\n",
    "    comptage_presence = verification_presence_id_table(id_fichier, \n",
    "                                                      conn, \n",
    "                                                      document_budgetaire) \n",
    "    if comptage_presence[0] > 0 : \n",
    "       #print(f'Fichier {id_fichier} déjà extrait dans la base ! ')\n",
    "       pass \n",
    "    elif comptage_presence[0] == 0 :\n",
    "     try : \n",
    "      fichier_parse = parse_fichier(file)\n",
    "      chemin_exer = fichier_parse['DocumentBudgetaire']['Budget']['BlocBudget']['Exer']\n",
    "      chemin_nomenclature = fichier_parse['DocumentBudgetaire']['Budget']['EnTeteBudget']['Nomenclature']\n",
    "      dict_metadonnees = {'Id_Fichier' : id_fichier, \n",
    "                         'Nomenclature' : chemin_nomenclature.get('@V'),\n",
    "                         'Exer' : chemin_exer.get('@V')}\n",
    "      dict_id = {'Id_Fichier' : id_fichier}\n",
    "      val_natfonc = fichier_parse['DocumentBudgetaire']['Budget']['BlocBudget']['NatFonc']['@V']\n",
    "\n",
    "      #extraction et insertion doc budget (table centrale)\n",
    "      df_doc_budget = extraction_document_budgetaire(fichier_parse, dictionnaire_id= dict_id)\n",
    "      df_doc_budget = transcodage_bloc(df_doc_budget, dico_transco)\n",
    "      df_doc_budget = mise_au_norme_document_budgetaire(df_doc_budget, class_doc_budg = document_budgetaire)\n",
    "      df_doc_budget = ajout_data_siren(df_doc_budget, engine)\n",
    "      df_doc_budget.to_sql('document_budgetaire', engine ,if_exists = 'append', index = False, method = 'multi')\n",
    "\n",
    "      #df_budget\n",
    "      df_budget = extraction_budget(fichier_parse, dict_metadonnees)\n",
    "      df_budget = pd.concat([df_budget, df_bloc_budget_vide])\n",
    "      df_budget = jointure_libelle_comptable(\n",
    "                      df_budget = df_budget, \n",
    "                      df_nature_chap = df_nature_chap,\n",
    "                      df_nature_compte = df_nature_compte, \n",
    "                      df_fonction_chap = df_fonction_chap, \n",
    "                      df_fonction_compte = df_fonction_compte, \n",
    "                      df_fonction_mixte = df_fonction_mixte,\n",
    "                      LISTE_COL_SUPPRESSION_BUDGET = LISTE_COL_SUPPRESSION_BUDGET,\n",
    "                      valeur_NatFonc = val_natfonc, \n",
    "      )\n",
    "      df_budget = transcodage_bloc(df_budget, dico_transco)\n",
    "      df_budget = nettoyage_colonnes(df_budget, LISTE_COL_MAJ_BUDGET)\n",
    "\n",
    "      df_budget.to_sql('bloc_budget', engine ,if_exists = 'append', index = False, method = 'multi')\n",
    "\n",
    "      df_anomalies = creation_df_anomalies(df_budget, dict_id)\n",
    "      if isinstance(df_anomalies, pd.DataFrame) :\n",
    "        df_anomalies.to_sql('anomalies', engine ,if_exists = 'append', index = False, method = 'multi')\n",
    "      else : \n",
    "        None\n",
    "      #Annexes \n",
    "      chemin_general_annexe = fichier_parse['DocumentBudgetaire']['Budget']['Annexes']\n",
    "      for data_annexe in LIST_ANNEXES : \n",
    "       annexe_maj = data_annexe.split('DATA_')[1]\n",
    "       data_annexe_min = data_annexe.lower()\n",
    "       try :\n",
    "        bloc_annexe = chemin_general_annexe[data_annexe][annexe_maj]\n",
    "        df_annexe = pd.DataFrame(extraction_annexe(bloc_annexe, dict_metadonnees))\n",
    "        df_annexe = transcodage_bloc(df_annexe, dico_transco)\n",
    "        df_annexe.to_sql(data_annexe_min, engine, if_exists = 'append', index = False, method = 'multi')\n",
    "       except Exception as e : \n",
    "         None \n",
    "\n",
    "        \n",
    "     except Exception as e : \n",
    "       logger.error(f\"Error processing file {id_fichier}: {e}\")\n",
    "  \n",
    "def get_files() : \n",
    "  liste_file = glob.glob(os.path.join('../fichiers20/todo_xml_20/test_1k/', \"*.gz\"))\n",
    "  return liste_file\n",
    "\n",
    "\n",
    "\n",
    "def main() : \n",
    " liste_fichier = get_files()\n",
    " engine = sqlalchemy.create_engine('postgresql://verzochia:verzochia@localhost:5432/db_v14')\n",
    " for fichier in liste_fichier : \n",
    "  operate_file(fichier, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mono(file, engine):\n",
    " \n",
    "  id_fichier = extraction_id(file)\n",
    "\n",
    "  if id_fichier is None :\n",
    "    logger.info(f\"Fichier {file}, déjà dans la base\")\n",
    "    pass \n",
    "\n",
    "  else :\n",
    "\n",
    "    conn = engine.connect()\n",
    "    metadata = MetaData()\n",
    "    metadata.reflect(engine) \n",
    "\n",
    "    table_bloc_budget = metadata.tables['bloc_budget'] \n",
    "    df_bloc_budget_vide = pd.DataFrame(columns=LISTE_COL_MINIMALE_BUDGET)\n",
    "\n",
    "    Base = declarative_base()\n",
    "\n",
    "    class document_budgetaire(Base) :\n",
    "     __table__ = Table('document_budgetaire', Base.metadata, autoload_with = engine)\n",
    "       \n",
    "    #Prep transco\n",
    "    df_transco = pd.read_sql('Select * from transcodage', engine)\n",
    "    dico_transco = {j['nom_champ']: eval(j['enum']) for i, j in df_transco.iterrows()}\n",
    "\n",
    "    #prep libelle\n",
    "    df_nature_compte = pd.read_sql('SELECT * FROM nature_compte', engine)\n",
    "    df_nature_chap = pd.read_sql('SELECT * FROM nature_chapitre', engine)\n",
    "    df_fonction_compte = pd.read_sql('SELECT * FROM fonction_compte', engine)\n",
    "    df_fonction_chap = pd.read_sql('SELECT * FROM fonction_chapitre', engine)\n",
    "    df_fonction_mixte = pd.read_sql('SELECT * FROM fonction_compte_mixte', engine)\n",
    "\n",
    "    comptage_presence = verification_presence_id_table(id_fichier, \n",
    "                                                      conn, \n",
    "                                                      document_budgetaire) \n",
    "    if comptage_presence[0] > 0 : \n",
    "       #print(f'Fichier {id_fichier} déjà extrait dans la base ! ')\n",
    "       pass \n",
    "    elif comptage_presence[0] == 0 :\n",
    "     try : \n",
    "      fichier_parse = parse_fichier(file)\n",
    "      chemin_exer = fichier_parse['DocumentBudgetaire']['Budget']['BlocBudget']['Exer']\n",
    "      chemin_nomenclature = fichier_parse['DocumentBudgetaire']['Budget']['EnTeteBudget']['Nomenclature']\n",
    "      dict_metadonnees = {'Id_Fichier' : id_fichier, \n",
    "                         'Nomenclature' : chemin_nomenclature.get('@V'),\n",
    "                         'Exer' : chemin_exer.get('@V')}\n",
    "      dict_id = {'Id_Fichier' : id_fichier}\n",
    "      val_natfonc = fichier_parse['DocumentBudgetaire']['Budget']['BlocBudget']['NatFonc']['@V']\n",
    "\n",
    "      #extraction et insertion doc budget (table centrale)\n",
    "      df_doc_budget = extraction_document_budgetaire(fichier_parse, dictionnaire_id= dict_id)\n",
    "      df_doc_budget = transcodage_bloc(df_doc_budget, dico_transco)\n",
    "      df_doc_budget = mise_au_norme_document_budgetaire(df_doc_budget, class_doc_budg = document_budgetaire)\n",
    "        \n",
    "     except Exception as e : \n",
    "       logger.error(f\"Error processing file {id_fichier}: {e}\")\n",
    "  return df_doc_budget\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "engine = sqlalchemy.create_engine('postgresql://verzochia:verzochia@localhost:5432/db_v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 84)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_parquet('../data/bloc_parquet/decoupage/bloc_budget_1.parquet')\n",
    "df1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15005625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count\n",
       "0  15005625"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_sql('''SELECT Count(b.*) from bloc_budget as b JOIN document_budgetaire as d  ON b.\"Id_Fichier\" = d.\"Id_Fichier\" WHERE d.\"NatFonc\" = '3' ''', engine)\n",
    "df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../airflow-docker/data_test/fichier_test_boto/786217.xml.gz'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a ='../data/todo_xml/786217.xml.gz'\n",
    "b ='../airflow-docker/data_test/fichier_test_boto/786217.xml.gz'\n",
    "import shutil \n",
    "shutil.copy(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
